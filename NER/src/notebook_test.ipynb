{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "import train\n",
    "import dataset as ds\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "\n",
    "import utils\n",
    "import os\n",
    "import conll2brat\n",
    "import glob\n",
    "import codecs\n",
    "import shutil\n",
    "import time\n",
    "import copy\n",
    "import evaluate\n",
    "import random\n",
    "import pickle\n",
    "import brat2conll\n",
    "import numpy as np\n",
    "import utils_nlp\n",
    "import distutils.util as distutils_util\n",
    "import configparser\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {'pretrained_model_folder':'../model',\n",
    "                      'dataset_text_folder':'../../../ML_EntityData/data/en',\n",
    "                      'character_embedding_dimension':25,\n",
    "                      'character_lstm_hidden_state_dimension':25,\n",
    "                      'check_for_digits_replaced_with_zeros':True,\n",
    "                      'check_for_lowercase':True,\n",
    "                      'debug':False,\n",
    "                      'dropout_rate':0.5,\n",
    "                      'experiment_name':'test',\n",
    "                      'freeze_token_embeddings':False,\n",
    "                      'gradient_clipping_value':5.0,\n",
    "                      'learning_rate':0.005,\n",
    "                      'load_only_pretrained_token_embeddings':False,\n",
    "                      'load_all_pretrained_token_embeddings':False,\n",
    "                      'main_evaluation_mode':'conll',\n",
    "                      'maximum_number_of_epochs':500,\n",
    "                      'number_of_cpu_threads':8,\n",
    "                      'number_of_gpus':0,\n",
    "                      'optimizer':'sgd',\n",
    "                      'output_folder':'../../../ML_EntityData/output',\n",
    "                      'patience':10,\n",
    "                      'plot_format':'pdf',\n",
    "                      'reload_character_embeddings':True,\n",
    "                      'reload_character_lstm':True,\n",
    "                      'reload_crf':True,\n",
    "                      'reload_feedforward':True,\n",
    "                      'reload_token_embeddings':True,\n",
    "                      'reload_token_lstm':True,\n",
    "                      'remap_unknown_tokens_to_unk':True,\n",
    "                      'spacylanguage':'en',\n",
    "                      'tagging_format':'bioes',\n",
    "                      'token_embedding_dimension':100,\n",
    "                      'token_lstm_hidden_state_dimension':100,\n",
    "                      'token_pretrained_embedding_filepath':'../../../ML_EntityData/embedding/glove.6B.100d.txt',\n",
    "                      'tokenizer':'spacy',\n",
    "                      'train_model':True,\n",
    "                      'use_character_lstm':True,\n",
    "                      'use_crf':True,\n",
    "                      'use_pretrained_model':False,\n",
    "                      'verbose':False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the validity of BRAT-formatted train set... Done.\n",
      "Checking compatibility between CONLL and BRAT for train_compatible_with_brat set ... Done.\n",
      "Checking validity of CONLL BIOES format... Done.\n",
      "Checking the validity of BRAT-formatted valid set... Done.\n",
      "Checking compatibility between CONLL and BRAT for valid_compatible_with_brat set ... Done.\n",
      "Checking validity of CONLL BIOES format... Done.\n",
      "Checking the validity of BRAT-formatted test set... Done.\n",
      "Checking compatibility between CONLL and BRAT for test_compatible_with_brat set ... Done.\n",
      "Checking validity of CONLL BIOES format... Done.\n",
      "Load dataset... done (43.67 seconds)\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "import dataset as ds\n",
    "# Load dataset\n",
    "dataset_filepaths, dataset_brat_folders = utils.get_valid_dataset_filepaths(parameters)\n",
    "dataset = ds.Dataset(verbose=False, debug=False)\n",
    "token_to_vector = dataset.load_dataset(dataset_filepaths, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linhpn.VISC\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedded_characters: Tensor(\"character_embedding/embedded_characters:0\", shape=(?, ?, 25), dtype=float32)\n",
      "embedded_tokens: Tensor(\"token_embedding/embedding_lookup:0\", shape=(?, 100), dtype=float32)\n",
      "token_lstm_input: Tensor(\"concatenate_token_and_character_vectors/token_lstm_input:0\", shape=(?, 150), dtype=float32)\n",
      "token_lstm_input_drop: Tensor(\"dropout/token_lstm_input_drop/mul:0\", shape=(?, 150), dtype=float32)\n",
      "token_lstm_input_drop_expanded: Tensor(\"dropout/token_lstm_input_drop_expanded:0\", shape=(1, ?, 150), dtype=float32)\n",
      "unary_scores_expanded: Tensor(\"crf/unary_scores_expanded:0\", shape=(1, ?, 19), dtype=float32)\n",
      "input_label_indices_flat_batch: Tensor(\"crf/input_label_indices_flat_batch:0\", shape=(1, ?), dtype=int32)\n",
      "sequence_lengths: Tensor(\"crf/sequence_lengths:0\", shape=(1,), dtype=int32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linhpn.VISC\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:96: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from BLSTM_CRF import Char_BLSTM_CRF\n",
    "# Create model lstm+crf\n",
    "session_conf = tf.ConfigProto(\n",
    "            intra_op_parallelism_threads=parameters['number_of_cpu_threads'],\n",
    "            inter_op_parallelism_threads=parameters['number_of_cpu_threads'],\n",
    "            device_count={'CPU': 1, 'GPU': parameters['number_of_gpus']},\n",
    "            allow_soft_placement=True,\n",
    "            # automatically choose an existing and supported device to run the operations in case the specified one doesn't exist\n",
    "            log_device_placement=False\n",
    "        )\n",
    "sess = tf.Session(config=session_conf)\n",
    "\n",
    "with sess.as_default():\n",
    "    # Create model and initialize or load pretrained model\n",
    "    ### Instantiate the model\n",
    "    model = Char_BLSTM_CRF(dataset=dataset, token_embedding_dimension=parameters['token_embedding_dimension'],\n",
    "                       character_lstm_hidden_state_dimension=parameters['character_lstm_hidden_state_dimension'],\n",
    "                       token_lstm_hidden_state_dimension=parameters['token_lstm_hidden_state_dimension'],\n",
    "                       character_embedding_dimension=parameters['character_embedding_dimension'],\n",
    "                       gradient_clipping_value=parameters['gradient_clipping_value'],\n",
    "                       learning_rate=parameters['learning_rate'],\n",
    "                       freeze_token_embeddings=parameters['freeze_token_embeddings'],\n",
    "                       optimizer=parameters['optimizer'],\n",
    "                       maximum_number_of_epochs=parameters['maximum_number_of_epochs'])\n",
    "\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load token embeddings... done (0.17 seconds)\n",
      "number_of_token_original_case_found: 14618\n",
      "number_of_token_lowercase_found: 11723\n",
      "number_of_token_digits_replaced_with_zeros_found: 119\n",
      "number_of_token_lowercase_and_digits_replaced_with_zeros_found: 16\n",
      "number_of_loaded_word_vectors: 26476\n",
      "dataset.vocabulary_size: 28984\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "model.load_pretrained_token_embeddings(sess, dataset,embedding_filepath=parameters['token_pretrained_embedding_filepath'],\n",
    "                                                       check_lowercase= parameters['check_for_lowercase'],check_digits=parameters['check_for_digits_replaced_with_zeros'],\n",
    "                                                       token_to_vector=token_to_vector)\n",
    "# Initial params_train\n",
    "transition_params_trained = np.random.rand(len(dataset.unique_labels) + 2,len(dataset.unique_labels) + 2)\n",
    "\n",
    "del token_to_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "import os\n",
    "import pickle\n",
    "stats_graph_folder, experiment_timestamp = utils.create_stats_graph_folder(parameters)\n",
    "\n",
    "        # Initialize and save execution details\n",
    "start_time = time.time()\n",
    "results = {}\n",
    "results['epoch'] = {}\n",
    "results['execution_details'] = {}\n",
    "results['execution_details']['train_start'] = start_time\n",
    "results['execution_details']['time_stamp'] = experiment_timestamp\n",
    "results['execution_details']['early_stop'] = False\n",
    "results['execution_details']['keyboard_interrupt'] = False\n",
    "results['execution_details']['num_epochs'] = 0\n",
    "results['model_options'] = copy.copy(parameters)\n",
    "\n",
    "model_folder = os.path.join(stats_graph_folder, 'model')\n",
    "utils.create_folder_if_not_exists(model_folder)\n",
    "\n",
    "pickle.dump(dataset, open(os.path.join(model_folder, 'dataset.pickle'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting epoch 0\n",
      "Training completed in 0.00 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.0085    0.0365    0.0138      1041\n",
      "     B-MISC     0.0049    0.0058    0.0053       858\n",
      "      B-ORG     0.0058    0.0020    0.0030      2485\n",
      "      B-PER     0.0211    0.0609    0.0314      4284\n",
      "      E-LOC     0.0141    0.0211    0.0169      1041\n",
      "     E-MISC     0.0067    0.0058    0.0063       858\n",
      "      E-ORG     0.0131    0.0294    0.0182      2485\n",
      "      E-PER     0.0667    0.0037    0.0071      4284\n",
      "      I-LOC     0.0003    0.0431    0.0005       116\n",
      "     I-MISC     0.0000    0.0000    0.0000       297\n",
      "      I-ORG     0.0016    0.0049    0.0024      1219\n",
      "      I-PER     0.0015    0.0369    0.0029       244\n",
      "          O     0.0000    0.0000    0.0000    168382\n",
      "      S-LOC     0.0162    0.0600    0.0255      6099\n",
      "     S-MISC     0.0192    0.0016    0.0029      2580\n",
      "      S-ORG     0.0130    0.4179    0.0253      3836\n",
      "      S-PER     0.0148    0.0026    0.0044      2316\n",
      "\n",
      "avg / total     0.0034    0.0120    0.0026    202425\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.0086    0.0470    0.0146       234\n",
      "     B-MISC     0.0000    0.0000    0.0000       257\n",
      "      B-ORG     0.0090    0.0044    0.0059       450\n",
      "      B-PER     0.0243    0.0632    0.0351      1234\n",
      "      E-LOC     0.0224    0.0256    0.0239       234\n",
      "     E-MISC     0.0000    0.0000    0.0000       257\n",
      "      E-ORG     0.0094    0.0311    0.0144       450\n",
      "      E-PER     0.1111    0.0049    0.0093      1234\n",
      "      I-LOC     0.0004    0.0870    0.0009        23\n",
      "     I-MISC     0.0000    0.0000    0.0000        89\n",
      "      I-ORG     0.0000    0.0000    0.0000       301\n",
      "      I-PER     0.0006    0.0137    0.0011        73\n",
      "          O     0.0000    0.0000    0.0000     42434\n",
      "      S-LOC     0.0223    0.0761    0.0344      1603\n",
      "     S-MISC     0.0189    0.0015    0.0028       665\n",
      "      S-ORG     0.0114    0.3951    0.0222       891\n",
      "      S-PER     0.0333    0.0049    0.0086       608\n",
      "\n",
      "avg / total     0.0051    0.0117    0.0030     51037\n",
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.0140    0.0690    0.0232       232\n",
      "     B-MISC     0.0022    0.0056    0.0032       177\n",
      "      B-ORG     0.0068    0.0017    0.0028       579\n",
      "      B-PER     0.0226    0.0599    0.0328      1086\n",
      "      E-LOC     0.0087    0.0129    0.0104       232\n",
      "     E-MISC     0.0175    0.0113    0.0137       177\n",
      "      E-ORG     0.0103    0.0207    0.0138       579\n",
      "      E-PER     0.0342    0.0037    0.0067      1086\n",
      "      I-LOC     0.0007    0.1200    0.0013        25\n",
      "     I-MISC     0.0000    0.0000    0.0000        39\n",
      "      I-ORG     0.0023    0.0078    0.0036       256\n",
      "      I-PER     0.0014    0.0286    0.0027        70\n",
      "          O     0.0000    0.0000    0.0000     37983\n",
      "      S-LOC     0.0189    0.0682    0.0296      1436\n",
      "     S-MISC     0.0120    0.0019    0.0033       525\n",
      "      S-ORG     0.0202    0.5074    0.0389      1082\n",
      "      S-PER     0.0093    0.0019    0.0031       531\n",
      "\n",
      "avg / total     0.0031    0.0165    0.0033     46095\n",
      "\n",
      "\n",
      "Starting epoch 1\n",
      "Training completed in 290.18 seconds\n",
      "Evaluate model on the train set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linhpn.VISC\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.8560    0.6282    0.7247      1041\n",
      "     B-MISC     0.7652    0.4709    0.5830       858\n",
      "      B-ORG     0.8258    0.6141    0.7044      2485\n",
      "      B-PER     0.9256    0.9414    0.9335      4284\n",
      "      E-LOC     0.8446    0.6215    0.7161      1041\n",
      "     E-MISC     0.6949    0.4406    0.5392       858\n",
      "      E-ORG     0.8450    0.6318    0.7230      2485\n",
      "      E-PER     0.9425    0.9458    0.9442      4284\n",
      "      I-LOC     0.0000    0.0000    0.0000       116\n",
      "     I-MISC     0.8000    0.0135    0.0265       297\n",
      "      I-ORG     0.8185    0.4512    0.5817      1219\n",
      "      I-PER     0.8587    0.3238    0.4702       244\n",
      "          O     0.0000    0.0000    0.0000       471\n",
      "      S-LOC     0.8897    0.9061    0.8978      6099\n",
      "     S-MISC     0.8906    0.6213    0.7320      2580\n",
      "      S-ORG     0.9052    0.7140    0.7983      3836\n",
      "      S-PER     0.9298    0.7094    0.8048      2316\n",
      "\n",
      "avg / total     0.8684    0.7362    0.7874     34514\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.8110    0.5684    0.6683       234\n",
      "     B-MISC     0.7143    0.4864    0.5787       257\n",
      "      B-ORG     0.7733    0.5156    0.6187       450\n",
      "      B-PER     0.9438    0.9530    0.9484      1234\n",
      "      E-LOC     0.8061    0.5684    0.6667       234\n",
      "     E-MISC     0.6821    0.4591    0.5488       257\n",
      "      E-ORG     0.7954    0.5356    0.6401       450\n",
      "      E-PER     0.9576    0.9522    0.9549      1234\n",
      "      I-LOC     0.0000    0.0000    0.0000        23\n",
      "     I-MISC     1.0000    0.0112    0.0222        89\n",
      "      I-ORG     0.8156    0.3821    0.5204       301\n",
      "      I-PER     0.8824    0.4110    0.5607        73\n",
      "          O     0.0000    0.0000    0.0000       114\n",
      "      S-LOC     0.8996    0.9283    0.9137      1603\n",
      "     S-MISC     0.9208    0.7173    0.8064       665\n",
      "      S-ORG     0.9037    0.7475    0.8182       891\n",
      "      S-PER     0.9060    0.7763    0.8361       608\n",
      "\n",
      "avg / total     0.8717    0.7551    0.7979      8717\n",
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.7461    0.6207    0.6776       232\n",
      "     B-MISC     0.5854    0.5424    0.5630       177\n",
      "      B-ORG     0.7911    0.6149    0.6919       579\n",
      "      B-PER     0.9158    0.9411    0.9282      1086\n",
      "      E-LOC     0.7474    0.6250    0.6808       232\n",
      "     E-MISC     0.5621    0.5367    0.5491       177\n",
      "      E-ORG     0.8054    0.6218    0.7018       579\n",
      "      E-PER     0.9346    0.9475    0.9410      1086\n",
      "      I-LOC     0.0000    0.0000    0.0000        25\n",
      "     I-MISC     1.0000    0.0256    0.0500        39\n",
      "      I-ORG     0.8027    0.4609    0.5856       256\n",
      "      I-PER     0.9412    0.2286    0.3678        70\n",
      "          O     0.0000    0.0000    0.0000       217\n",
      "      S-LOC     0.8408    0.9011    0.8699      1436\n",
      "     S-MISC     0.8691    0.6324    0.7321       525\n",
      "      S-ORG     0.8747    0.6580    0.7511      1082\n",
      "      S-PER     0.9192    0.6215    0.7416       531\n",
      "\n",
      "avg / total     0.8275    0.7264    0.7644      8329\n",
      "\n",
      "\n",
      "Starting epoch 2\n",
      "Training completed in 279.39 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9074    0.8194    0.8612      1041\n",
      "     B-MISC     0.7853    0.7121    0.7469       858\n",
      "      B-ORG     0.8655    0.8286    0.8466      2485\n",
      "      B-PER     0.9479    0.9818    0.9646      4284\n",
      "      E-LOC     0.9083    0.8280    0.8663      1041\n",
      "     E-MISC     0.7906    0.7261    0.7570       858\n",
      "      E-ORG     0.8723    0.8382    0.8549      2485\n",
      "      E-PER     0.9540    0.9883    0.9709      4284\n",
      "      I-LOC     1.0000    0.0172    0.0339       116\n",
      "     I-MISC     0.8279    0.3401    0.4821       297\n",
      "      I-ORG     0.7182    0.8655    0.7850      1219\n",
      "      I-PER     0.8280    0.8484    0.8381       244\n",
      "          O     0.0000    0.0000    0.0000       619\n",
      "      S-LOC     0.9540    0.9377    0.9458      6099\n",
      "     S-MISC     0.8833    0.8512    0.8670      2580\n",
      "      S-ORG     0.8991    0.8475    0.8725      3836\n",
      "      S-PER     0.9077    0.8916    0.8996      2316\n",
      "\n",
      "avg / total     0.8885    0.8692    0.8757     34662\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.8850    0.7564    0.8157       234\n",
      "     B-MISC     0.7534    0.6420    0.6933       257\n",
      "      B-ORG     0.7934    0.7511    0.7717       450\n",
      "      B-PER     0.9597    0.9838    0.9716      1234\n",
      "      E-LOC     0.8900    0.7607    0.8203       234\n",
      "     E-MISC     0.7851    0.6965    0.7381       257\n",
      "      E-ORG     0.8150    0.7733    0.7936       450\n",
      "      E-PER     0.9636    0.9862    0.9748      1234\n",
      "      I-LOC     0.0000    0.0000    0.0000        23\n",
      "     I-MISC     0.8065    0.2809    0.4167        89\n",
      "      I-ORG     0.7461    0.8007    0.7724       301\n",
      "      I-PER     0.8281    0.7260    0.7737        73\n",
      "          O     0.0000    0.0000    0.0000       147\n",
      "      S-LOC     0.9408    0.9513    0.9460      1603\n",
      "     S-MISC     0.9032    0.8842    0.8936       665\n",
      "      S-ORG     0.9014    0.8620    0.8812       891\n",
      "      S-PER     0.8834    0.9095    0.8963       608\n",
      "\n",
      "avg / total     0.8816    0.8650    0.8713      8750\n",
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.8249    0.7716    0.7973       232\n",
      "     B-MISC     0.6134    0.6723    0.6415       177\n",
      "      B-ORG     0.7983    0.8066    0.8024       579\n",
      "      B-PER     0.9536    0.9843    0.9687      1086\n",
      "      E-LOC     0.8108    0.7759    0.7930       232\n",
      "     E-MISC     0.6142    0.6836    0.6471       177\n",
      "      E-ORG     0.8072    0.8169    0.8120       579\n",
      "      E-PER     0.9545    0.9843    0.9692      1086\n",
      "      I-LOC     0.0000    0.0000    0.0000        25\n",
      "     I-MISC     0.7619    0.4103    0.5333        39\n",
      "      I-ORG     0.6809    0.8750    0.7658       256\n",
      "      I-PER     0.9310    0.7714    0.8438        70\n",
      "          O     0.0000    0.0000    0.0000       304\n",
      "      S-LOC     0.9201    0.9220    0.9210      1436\n",
      "     S-MISC     0.8230    0.8324    0.8277       525\n",
      "      S-ORG     0.9046    0.8327    0.8672      1082\n",
      "      S-PER     0.8869    0.8267    0.8558       531\n",
      "\n",
      "avg / total     0.8402    0.8403    0.8391      8416\n",
      "\n",
      "\n",
      "Starting epoch 3\n",
      "Training completed in 284.95 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.8930    0.8742    0.8835      1041\n",
      "     B-MISC     0.9087    0.6608    0.7652       858\n",
      "      B-ORG     0.8714    0.8757    0.8735      2485\n",
      "      B-PER     0.9623    0.9841    0.9731      4284\n",
      "      E-LOC     0.8936    0.8790    0.8862      1041\n",
      "     E-MISC     0.9259    0.6841    0.7869       858\n",
      "      E-ORG     0.8742    0.8809    0.8775      2485\n",
      "      E-PER     0.9655    0.9869    0.9761      4284\n",
      "      I-LOC     0.8810    0.3190    0.4684       116\n",
      "     I-MISC     0.8481    0.4512    0.5890       297\n",
      "      I-ORG     0.8437    0.8236    0.8335      1219\n",
      "      I-PER     0.9241    0.8484    0.8846       244\n",
      "          O     0.0000    0.0000    0.0000       426\n",
      "      S-LOC     0.9453    0.9606    0.9529      6099\n",
      "     S-MISC     0.9373    0.8395    0.8857      2580\n",
      "      S-ORG     0.9057    0.8884    0.8970      3836\n",
      "      S-PER     0.9114    0.9149    0.9132      2316\n",
      "\n",
      "avg / total     0.9112    0.8913    0.8991     34469\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.8750    0.7778    0.8235       234\n",
      "     B-MISC     0.8118    0.5875    0.6817       257\n",
      "      B-ORG     0.7887    0.8044    0.7965       450\n",
      "      B-PER     0.9682    0.9862    0.9771      1234\n",
      "      E-LOC     0.8708    0.7778    0.8217       234\n",
      "     E-MISC     0.8737    0.6459    0.7427       257\n",
      "      E-ORG     0.7991    0.8222    0.8105       450\n",
      "      E-PER     0.9682    0.9862    0.9771      1234\n",
      "      I-LOC     1.0000    0.2609    0.4138        23\n",
      "     I-MISC     0.7805    0.3596    0.4923        89\n",
      "      I-ORG     0.8439    0.7542    0.7965       301\n",
      "      I-PER     0.9273    0.6986    0.7969        73\n",
      "          O     0.0000    0.0000    0.0000        96\n",
      "      S-LOC     0.9379    0.9701    0.9537      1603\n",
      "     S-MISC     0.9171    0.8647    0.8901       665\n",
      "      S-ORG     0.9033    0.8810    0.8920       891\n",
      "      S-PER     0.8787    0.9178    0.8978       608\n",
      "\n",
      "avg / total     0.8981    0.8778    0.8850      8699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.8120    0.8190    0.8155       232\n",
      "     B-MISC     0.6687    0.6271    0.6472       177\n",
      "      B-ORG     0.8191    0.8290    0.8240       579\n",
      "      B-PER     0.9605    0.9843    0.9723      1086\n",
      "      E-LOC     0.7958    0.8233    0.8093       232\n",
      "     E-MISC     0.6905    0.6554    0.6725       177\n",
      "      E-ORG     0.8365    0.8480    0.8422       579\n",
      "      E-PER     0.9629    0.9807    0.9717      1086\n",
      "      I-LOC     0.8333    0.2000    0.3226        25\n",
      "     I-MISC     0.7586    0.5641    0.6471        39\n",
      "      I-ORG     0.7852    0.7852    0.7852       256\n",
      "      I-PER     0.9815    0.7571    0.8548        70\n",
      "          O     0.0000    0.0000    0.0000       225\n",
      "      S-LOC     0.9103    0.9325    0.9212      1436\n",
      "     S-MISC     0.8708    0.7962    0.8318       525\n",
      "      S-ORG     0.8915    0.8660    0.8786      1082\n",
      "      S-PER     0.8858    0.8475    0.8662       531\n",
      "\n",
      "avg / total     0.8613    0.8562    0.8577      8337\n",
      "\n",
      "\n",
      "Starting epoch 4\n",
      "Training completed in 282.80 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.8473    0.9011    0.8734      1041\n",
      "     B-MISC     0.8993    0.7075    0.7919       858\n",
      "      B-ORG     0.9027    0.8736    0.8879      2485\n",
      "      B-PER     0.9613    0.9869    0.9740      4284\n",
      "      E-LOC     0.8525    0.9049    0.8779      1041\n",
      "     E-MISC     0.9195    0.7191    0.8071       858\n",
      "      E-ORG     0.9049    0.8769    0.8907      2485\n",
      "      E-PER     0.9665    0.9909    0.9786      4284\n",
      "      I-LOC     0.8889    0.4138    0.5647       116\n",
      "     I-MISC     0.8571    0.5051    0.6356       297\n",
      "      I-ORG     0.8553    0.8532    0.8542      1219\n",
      "      I-PER     0.9241    0.8484    0.8846       244\n",
      "          O     0.0000    0.0000    0.0000       357\n",
      "      S-LOC     0.9610    0.9544    0.9577      6099\n",
      "     S-MISC     0.9266    0.8705    0.8977      2580\n",
      "      S-ORG     0.9378    0.8887    0.9126      3836\n",
      "      S-PER     0.9213    0.9253    0.9233      2316\n",
      "\n",
      "avg / total     0.9212    0.9009    0.9095     34400\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.8101    0.8932    0.8496       234\n",
      "     B-MISC     0.8031    0.6031    0.6889       257\n",
      "      B-ORG     0.8429    0.7867    0.8138       450\n",
      "      B-PER     0.9775    0.9862    0.9818      1234\n",
      "      E-LOC     0.8110    0.8803    0.8443       234\n",
      "     E-MISC     0.8500    0.6615    0.7440       257\n",
      "      E-ORG     0.8571    0.8000    0.8276       450\n",
      "      E-PER     0.9759    0.9862    0.9811      1234\n",
      "      I-LOC     0.7857    0.4783    0.5946        23\n",
      "     I-MISC     0.7143    0.3371    0.4580        89\n",
      "      I-ORG     0.8679    0.7641    0.8127       301\n",
      "      I-PER     0.9630    0.7123    0.8189        73\n",
      "          O     0.0000    0.0000    0.0000        93\n",
      "      S-LOC     0.9538    0.9663    0.9600      1603\n",
      "     S-MISC     0.9203    0.8857    0.9027       665\n",
      "      S-ORG     0.9198    0.9012    0.9104       891\n",
      "      S-PER     0.9075    0.9194    0.9134       608\n",
      "\n",
      "avg / total     0.9091    0.8867    0.8958      8696\n",
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.7057    0.8578    0.7743       232\n",
      "     B-MISC     0.6824    0.6554    0.6686       177\n",
      "      B-ORG     0.8336    0.7876    0.8099       579\n",
      "      B-PER     0.9674    0.9843    0.9758      1086\n",
      "      E-LOC     0.7050    0.8448    0.7686       232\n",
      "     E-MISC     0.6982    0.6667    0.6821       177\n",
      "      E-ORG     0.8467    0.8014    0.8234       579\n",
      "      E-PER     0.9631    0.9843    0.9736      1086\n",
      "      I-LOC     0.5625    0.3600    0.4390        25\n",
      "     I-MISC     0.7143    0.6410    0.6757        39\n",
      "      I-ORG     0.8211    0.7891    0.8048       256\n",
      "      I-PER     0.9655    0.8000    0.8750        70\n",
      "          O     0.0000    0.0000    0.0000       225\n",
      "      S-LOC     0.9263    0.9276    0.9269      1436\n",
      "     S-MISC     0.8538    0.8343    0.8439       525\n",
      "      S-ORG     0.8981    0.8549    0.8759      1082\n",
      "      S-PER     0.9139    0.8399    0.8754       531\n",
      "\n",
      "avg / total     0.8632    0.8540    0.8578      8337\n",
      "\n",
      "\n",
      "Starting epoch 5\n",
      "Training completed in 282.26 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9656    0.8098    0.8809      1041\n",
      "     B-MISC     0.9226    0.7506    0.8278       858\n",
      "      B-ORG     0.8281    0.9441    0.8823      2485\n",
      "      B-PER     0.9746    0.9865    0.9805      4284\n",
      "      E-LOC     0.9690    0.8108    0.8828      1041\n",
      "     E-MISC     0.9414    0.7681    0.8460       858\n",
      "      E-ORG     0.8330    0.9493    0.8873      2485\n",
      "      E-PER     0.9779    0.9902    0.9840      4284\n",
      "      I-LOC     0.9020    0.3966    0.5509       116\n",
      "     I-MISC     0.8708    0.6128    0.7194       297\n",
      "      I-ORG     0.7642    0.9360    0.8414      1219\n",
      "      I-PER     0.9146    0.9221    0.9184       244\n",
      "          O     0.0000    0.0000    0.0000       537\n",
      "      S-LOC     0.9723    0.9541    0.9631      6099\n",
      "     S-MISC     0.9771    0.8450    0.9063      2580\n",
      "      S-ORG     0.9054    0.9260    0.9156      3836\n",
      "      S-PER     0.9343    0.9331    0.9337      2316\n",
      "\n",
      "avg / total     0.9170    0.9100    0.9109     34580\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9659    0.7265    0.8293       234\n",
      "     B-MISC     0.8235    0.6537    0.7289       257\n",
      "      B-ORG     0.6988    0.8711    0.7755       450\n",
      "      B-PER     0.9797    0.9773    0.9785      1234\n",
      "      E-LOC     0.9826    0.7222    0.8325       234\n",
      "     E-MISC     0.8738    0.7004    0.7775       257\n",
      "      E-ORG     0.7117    0.8889    0.7905       450\n",
      "      E-PER     0.9789    0.9765    0.9777      1234\n",
      "      I-LOC     1.0000    0.2609    0.4138        23\n",
      "     I-MISC     0.7843    0.4494    0.5714        89\n",
      "      I-ORG     0.6989    0.8405    0.7632       301\n",
      "      I-PER     0.9444    0.6986    0.8031        73\n",
      "          O     0.0000    0.0000    0.0000       152\n",
      "      S-LOC     0.9601    0.9613    0.9607      1603\n",
      "     S-MISC     0.9613    0.8602    0.9079       665\n",
      "      S-ORG     0.8986    0.9248    0.9115       891\n",
      "      S-PER     0.9048    0.9227    0.9137       608\n",
      "\n",
      "avg / total     0.8961    0.8838    0.8858      8755\n",
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9021    0.7543    0.8216       232\n",
      "     B-MISC     0.6497    0.6497    0.6497       177\n",
      "      B-ORG     0.7375    0.8929    0.8078       579\n",
      "      B-PER     0.9807    0.9825    0.9816      1086\n",
      "      E-LOC     0.8974    0.7543    0.8197       232\n",
      "     E-MISC     0.6723    0.6723    0.6723       177\n",
      "      E-ORG     0.7418    0.8981    0.8125       579\n",
      "      E-PER     0.9779    0.9788    0.9784      1086\n",
      "      I-LOC     0.4375    0.2800    0.3415        25\n",
      "     I-MISC     0.6579    0.6410    0.6494        39\n",
      "      I-ORG     0.6725    0.8984    0.7692       256\n",
      "      I-PER     0.9538    0.8857    0.9185        70\n",
      "          O     0.0000    0.0000    0.0000       333\n",
      "      S-LOC     0.9389    0.9206    0.9297      1436\n",
      "     S-MISC     0.9013    0.7829    0.8379       525\n",
      "      S-ORG     0.8662    0.8974    0.8815      1082\n",
      "      S-PER     0.9302    0.8531    0.8900       531\n",
      "\n",
      "avg / total     0.8482    0.8564    0.8500      8445\n",
      "\n",
      "\n",
      "Starting epoch 6\n",
      "Training completed in 285.48 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9197    0.8915    0.9054      1041\n",
      "     B-MISC     0.9302    0.7611    0.8372       858\n",
      "      B-ORG     0.9036    0.8861    0.8948      2485\n",
      "      B-PER     0.9549    0.9890    0.9717      4284\n",
      "      E-LOC     0.9207    0.8924    0.9063      1041\n",
      "     E-MISC     0.9358    0.7646    0.8416       858\n",
      "      E-ORG     0.9061    0.8897    0.8979      2485\n",
      "      E-PER     0.9599    0.9935    0.9764      4284\n",
      "      I-LOC     0.8676    0.5086    0.6413       116\n",
      "     I-MISC     0.8724    0.5758    0.6937       297\n",
      "      I-ORG     0.6879    0.9565    0.8003      1219\n",
      "      I-PER     0.8947    0.9057    0.9002       244\n",
      "          O     0.0000    0.0000    0.0000       547\n",
      "      S-LOC     0.9720    0.9620    0.9670      6099\n",
      "     S-MISC     0.9478    0.8802    0.9128      2580\n",
      "      S-ORG     0.9725    0.8853    0.9269      3836\n",
      "      S-PER     0.8707    0.9564    0.9115      2316\n",
      "\n",
      "avg / total     0.9180    0.9089    0.9113     34590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.8718    0.8718    0.8718       234\n",
      "     B-MISC     0.8390    0.6693    0.7446       257\n",
      "      B-ORG     0.7852    0.7800    0.7826       450\n",
      "      B-PER     0.9650    0.9822    0.9735      1234\n",
      "      E-LOC     0.8793    0.8718    0.8755       234\n",
      "     E-MISC     0.8738    0.7004    0.7775       257\n",
      "      E-ORG     0.8180    0.8089    0.8134       450\n",
      "      E-PER     0.9650    0.9822    0.9735      1234\n",
      "      I-LOC     0.8421    0.6957    0.7619        23\n",
      "     I-MISC     0.8235    0.4719    0.6000        89\n",
      "      I-ORG     0.6417    0.9103    0.7527       301\n",
      "      I-PER     0.9123    0.7123    0.8000        73\n",
      "          O     0.0000    0.0000    0.0000       174\n",
      "      S-LOC     0.9598    0.9688    0.9643      1603\n",
      "     S-MISC     0.9481    0.8782    0.9118       665\n",
      "      S-ORG     0.9455    0.8575    0.8994       891\n",
      "      S-PER     0.8297    0.9375    0.8803       608\n",
      "\n",
      "avg / total     0.8911    0.8834    0.8847      8777\n",
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.7826    0.8534    0.8165       232\n",
      "     B-MISC     0.6706    0.6441    0.6571       177\n",
      "      B-ORG     0.7912    0.8117    0.8014       579\n",
      "      B-PER     0.9684    0.9890    0.9786      1086\n",
      "      E-LOC     0.7756    0.8491    0.8107       232\n",
      "     E-MISC     0.6941    0.6667    0.6801       177\n",
      "      E-ORG     0.7933    0.8152    0.8041       579\n",
      "      E-PER     0.9658    0.9871    0.9763      1086\n",
      "      I-LOC     0.6000    0.4800    0.5333        25\n",
      "     I-MISC     0.7059    0.6154    0.6575        39\n",
      "      I-ORG     0.5590    0.9062    0.6915       256\n",
      "      I-PER     0.9559    0.9286    0.9420        70\n",
      "          O     0.0000    0.0000    0.0000       355\n",
      "      S-LOC     0.9368    0.9283    0.9325      1436\n",
      "     S-MISC     0.8760    0.8343    0.8546       525\n",
      "      S-ORG     0.9268    0.8429    0.8829      1082\n",
      "      S-PER     0.8486    0.8870    0.8674       531\n",
      "\n",
      "avg / total     0.8423    0.8506    0.8447      8467\n",
      "\n",
      "\n",
      "Starting epoch 7\n",
      "Training completed in 280.74 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9315    0.9280    0.9297      1041\n",
      "     B-MISC     0.8454    0.8986    0.8712       858\n",
      "      B-ORG     0.9514    0.9066    0.9285      2485\n",
      "      B-PER     0.9812    0.9874    0.9843      4284\n",
      "      E-LOC     0.9279    0.9270    0.9274      1041\n",
      "     E-MISC     0.8364    0.8939    0.8642       858\n",
      "      E-ORG     0.9524    0.9091    0.9302      2485\n",
      "      E-PER     0.9835    0.9900    0.9867      4284\n",
      "      I-LOC     0.8734    0.5948    0.7077       116\n",
      "     I-MISC     0.8192    0.7475    0.7817       297\n",
      "      I-ORG     0.9233    0.8893    0.9060      1219\n",
      "      I-PER     0.9485    0.9057    0.9266       244\n",
      "          O     0.0000    0.0000    0.0000       269\n",
      "      S-LOC     0.9709    0.9677    0.9693      6099\n",
      "     S-MISC     0.9303    0.9058    0.9179      2580\n",
      "      S-ORG     0.9700    0.9020    0.9348      3836\n",
      "      S-PER     0.9499    0.9408    0.9453      2316\n",
      "\n",
      "avg / total     0.9463    0.9305    0.9380     34312\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.8612    0.9017    0.8810       234\n",
      "     B-MISC     0.7384    0.8016    0.7687       257\n",
      "      B-ORG     0.8841    0.7800    0.8288       450\n",
      "      B-PER     0.9886    0.9806    0.9845      1234\n",
      "      E-LOC     0.8595    0.8889    0.8739       234\n",
      "     E-MISC     0.7589    0.8327    0.7941       257\n",
      "      E-ORG     0.9020    0.7978    0.8467       450\n",
      "      E-PER     0.9869    0.9789    0.9829      1234\n",
      "      I-LOC     0.7059    0.5217    0.6000        23\n",
      "     I-MISC     0.5357    0.5056    0.5202        89\n",
      "      I-ORG     0.9289    0.7375    0.8222       301\n",
      "      I-PER     0.9623    0.6986    0.8095        73\n",
      "          O     0.0000    0.0000    0.0000        96\n",
      "      S-LOC     0.9508    0.9769    0.9637      1603\n",
      "     S-MISC     0.9209    0.8932    0.9069       665\n",
      "      S-ORG     0.9412    0.8979    0.9190       891\n",
      "      S-PER     0.9097    0.9112    0.9104       608\n",
      "\n",
      "avg / total     0.9163    0.8979    0.9060      8699\n",
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.7213    0.8922    0.7977       232\n",
      "     B-MISC     0.6009    0.7232    0.6564       177\n",
      "      B-ORG     0.8571    0.8083    0.8320       579\n",
      "      B-PER     0.9807    0.9807    0.9807      1086\n",
      "      E-LOC     0.7228    0.8879    0.7969       232\n",
      "     E-MISC     0.6204    0.7571    0.6819       177\n",
      "      E-ORG     0.8674    0.8135    0.8396       579\n",
      "      E-PER     0.9807    0.9807    0.9807      1086\n",
      "      I-LOC     0.4643    0.5200    0.4906        25\n",
      "     I-MISC     0.6190    0.6667    0.6420        39\n",
      "      I-ORG     0.8031    0.8125    0.8078       256\n",
      "      I-PER     0.9833    0.8429    0.9077        70\n",
      "          O     0.0000    0.0000    0.0000       253\n",
      "      S-LOC     0.9325    0.9338    0.9332      1436\n",
      "     S-MISC     0.8362    0.8457    0.8409       525\n",
      "      S-ORG     0.9146    0.8614    0.8872      1082\n",
      "      S-PER     0.9419    0.8550    0.8963       531\n",
      "\n",
      "avg / total     0.8676    0.8632    0.8643      8365\n",
      "\n",
      "\n",
      "Starting epoch 8\n",
      "Training completed in 282.56 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9160    0.9328    0.9243      1041\n",
      "     B-MISC     0.8943    0.8578    0.8757       858\n",
      "      B-ORG     0.9570    0.8873    0.9209      2485\n",
      "      B-PER     0.9765    0.9911    0.9838      4284\n",
      "      E-LOC     0.9127    0.9337    0.9231      1041\n",
      "     E-MISC     0.8933    0.8590    0.8758       858\n",
      "      E-ORG     0.9588    0.8889    0.9225      2485\n",
      "      E-PER     0.9798    0.9939    0.9868      4284\n",
      "      I-LOC     0.8391    0.6293    0.7192       116\n",
      "     I-MISC     0.8664    0.6768    0.7599       297\n",
      "      I-ORG     0.9313    0.8786    0.9042      1219\n",
      "      I-PER     0.9256    0.9180    0.9218       244\n",
      "          O     0.0000    0.0000    0.0000       189\n",
      "      S-LOC     0.9738    0.9697    0.9717      6099\n",
      "     S-MISC     0.9532    0.9000    0.9258      2580\n",
      "      S-ORG     0.9650    0.9202    0.9421      3836\n",
      "      S-PER     0.9460    0.9525    0.9492      2316\n",
      "\n",
      "avg / total     0.9519    0.9311    0.9410     34232\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.8419    0.9103    0.8747       234\n",
      "     B-MISC     0.7917    0.7393    0.7646       257\n",
      "      B-ORG     0.8871    0.7511    0.8135       450\n",
      "      B-PER     0.9798    0.9830    0.9814      1234\n",
      "      E-LOC     0.8367    0.8974    0.8660       234\n",
      "     E-MISC     0.8148    0.7704    0.7920       257\n",
      "      E-ORG     0.9005    0.7644    0.8269       450\n",
      "      E-PER     0.9790    0.9822    0.9806      1234\n",
      "      I-LOC     0.7143    0.6522    0.6818        23\n",
      "     I-MISC     0.6885    0.4719    0.5600        89\n",
      "      I-ORG     0.9271    0.7608    0.8358       301\n",
      "      I-PER     0.9444    0.6986    0.8031        73\n",
      "          O     0.0000    0.0000    0.0000        67\n",
      "      S-LOC     0.9570    0.9726    0.9647      1603\n",
      "     S-MISC     0.9469    0.8857    0.9153       665\n",
      "      S-ORG     0.9356    0.9136    0.9245       891\n",
      "      S-PER     0.9095    0.9260    0.9177       608\n",
      "\n",
      "avg / total     0.9231    0.8973    0.9088      8670\n",
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.7289    0.8922    0.8023       232\n",
      "     B-MISC     0.6178    0.6667    0.6413       177\n",
      "      B-ORG     0.8726    0.7807    0.8241       579\n",
      "      B-PER     0.9727    0.9853    0.9790      1086\n",
      "      E-LOC     0.7314    0.8922    0.8039       232\n",
      "     E-MISC     0.6474    0.6949    0.6703       177\n",
      "      E-ORG     0.8764    0.7841    0.8277       579\n",
      "      E-PER     0.9718    0.9834    0.9776      1086\n",
      "      I-LOC     0.4286    0.4800    0.4528        25\n",
      "     I-MISC     0.6216    0.5897    0.6053        39\n",
      "      I-ORG     0.8048    0.7891    0.7968       256\n",
      "      I-PER     0.9538    0.8857    0.9185        70\n",
      "          O     0.0000    0.0000    0.0000       230\n",
      "      S-LOC     0.9377    0.9325    0.9351      1436\n",
      "     S-MISC     0.8608    0.8248    0.8424       525\n",
      "      S-ORG     0.8965    0.8725    0.8843      1082\n",
      "      S-PER     0.9122    0.8606    0.8857       531\n",
      "\n",
      "avg / total     0.8688    0.8596    0.8633      8342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting epoch 9\n",
      "Training completed in 281.41 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9466    0.9366    0.9416      1041\n",
      "     B-MISC     0.9136    0.8753    0.8940       858\n",
      "      B-ORG     0.9453    0.9380    0.9416      2485\n",
      "      B-PER     0.9839    0.9874    0.9857      4284\n",
      "      E-LOC     0.9427    0.9328    0.9377      1041\n",
      "     E-MISC     0.9113    0.8741    0.8923       858\n",
      "      E-ORG     0.9457    0.9384    0.9420      2485\n",
      "      E-PER     0.9865    0.9897    0.9881      4284\n",
      "      I-LOC     0.8641    0.7672    0.8128       116\n",
      "     I-MISC     0.9114    0.7273    0.8090       297\n",
      "      I-ORG     0.9354    0.9147    0.9249      1219\n",
      "      I-PER     0.9492    0.9180    0.9333       244\n",
      "          O     0.0000    0.0000    0.0000       292\n",
      "      S-LOC     0.9758    0.9731    0.9745      6099\n",
      "     S-MISC     0.9145    0.9411    0.9276      2580\n",
      "      S-ORG     0.9667    0.9320    0.9490      3836\n",
      "      S-PER     0.9420    0.9611    0.9515      2316\n",
      "\n",
      "avg / total     0.9500    0.9433    0.9464     34335\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9181    0.9103    0.9142       234\n",
      "     B-MISC     0.8125    0.7588    0.7847       257\n",
      "      B-ORG     0.8635    0.8578    0.8606       450\n",
      "      B-PER     0.9861    0.9773    0.9817      1234\n",
      "      E-LOC     0.9174    0.9017    0.9095       234\n",
      "     E-MISC     0.8465    0.7938    0.8193       257\n",
      "      E-ORG     0.8817    0.8778    0.8797       450\n",
      "      E-PER     0.9845    0.9765    0.9805      1234\n",
      "      I-LOC     0.8636    0.8261    0.8444        23\n",
      "     I-MISC     0.8182    0.5056    0.6250        89\n",
      "      I-ORG     0.9014    0.8505    0.8752       301\n",
      "      I-PER     0.9630    0.7123    0.8189        73\n",
      "          O     0.0000    0.0000    0.0000       110\n",
      "      S-LOC     0.9618    0.9726    0.9671      1603\n",
      "     S-MISC     0.8971    0.9173    0.9071       665\n",
      "      S-ORG     0.9413    0.9181    0.9295       891\n",
      "      S-PER     0.8880    0.9391    0.9129       608\n",
      "\n",
      "avg / total     0.9209    0.9119    0.9157      8713\n",
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.7731    0.8664    0.8171       232\n",
      "     B-MISC     0.6158    0.6610    0.6376       177\n",
      "      B-ORG     0.8373    0.8532    0.8452       579\n",
      "      B-PER     0.9807    0.9816    0.9811      1086\n",
      "      E-LOC     0.7761    0.8664    0.8187       232\n",
      "     E-MISC     0.6561    0.7006    0.6776       177\n",
      "      E-ORG     0.8433    0.8549    0.8491       579\n",
      "      E-PER     0.9798    0.9825    0.9811      1086\n",
      "      I-LOC     0.5333    0.6400    0.5818        25\n",
      "     I-MISC     0.6389    0.5897    0.6133        39\n",
      "      I-ORG     0.7734    0.8398    0.8052       256\n",
      "      I-PER     0.9841    0.8857    0.9323        70\n",
      "          O     0.0000    0.0000    0.0000       303\n",
      "      S-LOC     0.9338    0.9338    0.9338      1436\n",
      "     S-MISC     0.8007    0.8724    0.8350       525\n",
      "      S-ORG     0.9084    0.8799    0.8939      1082\n",
      "      S-PER     0.9154    0.8757    0.8951       531\n",
      "\n",
      "avg / total     0.8582    0.8671    0.8623      8415\n",
      "\n",
      "\n",
      "Starting epoch 10\n",
      "Training completed in 298.56 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9452    0.9270    0.9360      1041\n",
      "     B-MISC     0.9228    0.8776    0.8996       858\n",
      "      B-ORG     0.9596    0.9187    0.9387      2485\n",
      "      B-PER     0.9694    0.9925    0.9809      4284\n",
      "      E-LOC     0.9443    0.9280    0.9360      1041\n",
      "     E-MISC     0.9252    0.8800    0.9020       858\n",
      "      E-ORG     0.9596    0.9187    0.9387      2485\n",
      "      E-PER     0.9735    0.9960    0.9847      4284\n",
      "      I-LOC     0.9342    0.6121    0.7396       116\n",
      "     I-MISC     0.9000    0.7576    0.8227       297\n",
      "      I-ORG     0.9133    0.9245    0.9189      1219\n",
      "      I-PER     0.8851    0.9467    0.9149       244\n",
      "          O     0.0000    0.0000    0.0000       295\n",
      "      S-LOC     0.9822    0.9695    0.9758      6099\n",
      "     S-MISC     0.9494    0.9236    0.9363      2580\n",
      "      S-ORG     0.9622    0.9416    0.9518      3836\n",
      "      S-PER     0.9084    0.9672    0.9368      2316\n",
      "\n",
      "avg / total     0.9490    0.9414    0.9448     34338\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9076    0.9231    0.9153       234\n",
      "     B-MISC     0.8058    0.7588    0.7816       257\n",
      "      B-ORG     0.8920    0.7889    0.8373       450\n",
      "      B-PER     0.9705    0.9870    0.9787      1234\n",
      "      E-LOC     0.9025    0.9103    0.9064       234\n",
      "     E-MISC     0.8354    0.7899    0.8120       257\n",
      "      E-ORG     0.9175    0.8156    0.8635       450\n",
      "      E-PER     0.9705    0.9878    0.9791      1234\n",
      "      I-LOC     0.8000    0.6957    0.7442        23\n",
      "     I-MISC     0.7500    0.5056    0.6040        89\n",
      "      I-ORG     0.9112    0.7841    0.8429       301\n",
      "      I-PER     0.8966    0.7123    0.7939        73\n",
      "          O     0.0000    0.0000    0.0000       107\n",
      "      S-LOC     0.9642    0.9750    0.9696      1603\n",
      "     S-MISC     0.9249    0.8887    0.9064       665\n",
      "      S-ORG     0.9199    0.9147    0.9173       891\n",
      "      S-PER     0.8515    0.9523    0.8991       608\n",
      "\n",
      "avg / total     0.9159    0.9051    0.9094      8710\n",
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.7736    0.8836    0.8249       232\n",
      "     B-MISC     0.6302    0.6836    0.6558       177\n",
      "      B-ORG     0.8787    0.8135    0.8448       579\n",
      "      B-PER     0.9686    0.9926    0.9804      1086\n",
      "      E-LOC     0.7736    0.8836    0.8249       232\n",
      "     E-MISC     0.6562    0.7119    0.6829       177\n",
      "      E-ORG     0.8822    0.8152    0.8474       579\n",
      "      E-PER     0.9677    0.9917    0.9795      1086\n",
      "      I-LOC     0.6957    0.6400    0.6667        25\n",
      "     I-MISC     0.6757    0.6410    0.6579        39\n",
      "      I-ORG     0.7778    0.8477    0.8112       256\n",
      "      I-PER     0.9714    0.9714    0.9714        70\n",
      "          O     0.0000    0.0000    0.0000       276\n",
      "      S-LOC     0.9430    0.9331    0.9380      1436\n",
      "     S-MISC     0.8423    0.8343    0.8383       525\n",
      "      S-ORG     0.8780    0.8909    0.8844      1082\n",
      "      S-PER     0.8785    0.8851    0.8818       531\n",
      "\n",
      "avg / total     0.8623    0.8695    0.8653      8388\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "bad_counter = 0  # number of epochs with no improvement on the validation test in terms of F1-score\n",
    "previous_best_valid_f1_score = 0\n",
    "epoch_number = -1\n",
    "\n",
    "while True:\n",
    "\n",
    "    step = 0\n",
    "    epoch_number += 1\n",
    "    print('\\nStarting epoch {0}'.format(epoch_number))\n",
    "\n",
    "    epoch_start_time = time.time()\n",
    "\n",
    "    if epoch_number != 0:\n",
    "        # Train model: loop over all sequences of training set with shuffling\n",
    "        sequence_numbers = list(range(len(dataset.token_indices['train'])))\n",
    "        random.shuffle(sequence_numbers)\n",
    "        for sequence_number in sequence_numbers:\n",
    "            transition_params_trained = train.train_step(sess, dataset, sequence_number, model, parameters['dropout_rate'])\n",
    "            step += 1\n",
    "            if step % 10 == 0:\n",
    "                print('Training {0:.2f}% done'.format(step / len(sequence_numbers) * 100), end='\\r', flush=True)\n",
    "\n",
    "    epoch_elapsed_training_time = time.time() - epoch_start_time\n",
    "    print('Training completed in {0:.2f} seconds'.format(epoch_elapsed_training_time), flush=True)\n",
    "\n",
    "    y_pred, y_true, output_filepaths = train.predict_labels_lite(sess=sess,model= model,transition_params_trained= transition_params_trained,\n",
    "                                                                         dataset=dataset,epoch_number= epoch_number,\n",
    "                                                                        stats_graph_folder= stats_graph_folder,dataset_filepaths= dataset_filepaths,\n",
    "                                                                        tagging_format= parameters['tagging_format'], main_evaluation_mode=parameters['main_evaluation_mode'],use_crf=parameters['use_crf'])\n",
    "\n",
    "       \n",
    "    model.saver.save(sess, os.path.join(model_folder, 'model_{0:05d}.ckpt'.format(epoch_number)))\n",
    "        \n",
    "    if epoch_number >= 10 :\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "prediction_count=0\n",
    "\n",
    "\n",
    "def predict(text):\n",
    "    #         if prediction_count == 1:\n",
    "    parameters['dataset_text_folder'] = os.path.join('..', 'data', 'temp')\n",
    "    stats_graph_folder, _ = utils.create_stats_graph_folder(parameters)\n",
    "\n",
    "    # Update the deploy folder, file, and dataset\n",
    "    dataset_type = 'deploy'\n",
    "    ### Delete all deployment data\n",
    "    for filepath in glob.glob(os.path.join(parameters['dataset_text_folder'], '{0}*'.format(dataset_type))):\n",
    "        if os.path.isdir(filepath):\n",
    "            shutil.rmtree(filepath)\n",
    "        else:\n",
    "            os.remove(filepath)\n",
    "    ### Create brat folder and file\n",
    "    dataset_brat_deploy_folder = os.path.join(parameters['dataset_text_folder'], dataset_type)\n",
    "    utils.create_folder_if_not_exists(dataset_brat_deploy_folder)\n",
    "    dataset_brat_deploy_filepath = os.path.join(dataset_brat_deploy_folder, 'temp_{0}.txt'.format(\n",
    "        str(prediction_count).zfill(5)))  # self._get_dataset_brat_deploy_filepath(dataset_brat_deploy_folder)\n",
    "    with codecs.open(dataset_brat_deploy_filepath, 'w', 'UTF-8') as f:\n",
    "        f.write(text)\n",
    "    ### Update deploy filepaths\n",
    "    dataset_filepaths, dataset_brat_folders = utils.get_valid_dataset_filepaths(parameters,\n",
    "                                                                           dataset_types=[dataset_type])\n",
    "    dataset_filepaths.update(dataset_filepaths)\n",
    "    dataset_brat_folders.update(dataset_brat_folders)\n",
    "    ### Update the dataset for the new deploy set\n",
    "    dataset.update_dataset(dataset_filepaths, [dataset_type])\n",
    "\n",
    "    # Predict labels and output brat\n",
    "    output_filepaths = {}\n",
    "    prediction_output = train.prediction_step(sess, dataset, dataset_type, model,\n",
    "                                              transition_params_trained, stats_graph_folder,\n",
    "                                              prediction_count, dataset_filepaths, parameters['tagging_format'],\n",
    "                                              parameters['main_evaluation_mode'])\n",
    "    _, _, output_filepaths[dataset_type] = prediction_output\n",
    "    conll2brat.output_brat(output_filepaths, dataset_brat_folders, stats_graph_folder, overwrite=True)\n",
    "\n",
    "    # Print and output result\n",
    "    text_filepath = os.path.join(stats_graph_folder, 'brat', 'deploy',\n",
    "                                 os.path.basename(dataset_brat_deploy_filepath))\n",
    "    annotation_filepath = os.path.join(stats_graph_folder, 'brat', 'deploy', '{0}.ann'.format(\n",
    "        utils.get_basename_without_extension(dataset_brat_deploy_filepath)))\n",
    "    text2, entities = brat2conll.get_entities_from_brat(text_filepath, annotation_filepath, verbose=True)\n",
    "    assert (text == text2)\n",
    "    return entities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatting deploy set from BRAT to CONLL... Done.\n",
      "Converting CONLL from BIO to BIOES format... Done.\n",
      "Predict labels for the deploy set\n",
      "Formatting 000_deploy set from CONLL to BRAT... Done.\n",
      "\n",
      "text:\n",
      "my name Is Ngoc Linh\n",
      "\n",
      "entity: {'id': 'T1', 'type': 'PER', 'start': 11, 'end': 20, 'text': 'Ngoc Linh'}\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'end': 20, 'id': 'T1', 'start': 11, 'text': 'Ngoc Linh', 'type': 'PER'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict('my name Is Ngoc Linh')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
