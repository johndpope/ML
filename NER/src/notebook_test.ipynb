{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "import train\n",
    "import dataset as ds\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "\n",
    "import utils\n",
    "import os\n",
    "import conll2brat\n",
    "import glob\n",
    "import codecs\n",
    "import shutil\n",
    "import time\n",
    "import copy\n",
    "import evaluate\n",
    "import random\n",
    "import pickle\n",
    "import brat2conll\n",
    "import numpy as np\n",
    "import utils_nlp\n",
    "import distutils.util as distutils_util\n",
    "import configparser\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'pretrained_model_folder':'../model',\n",
    "                      'dataset_text_folder':'../../../ML_EntityData/data/en',\n",
    "                      'character_embedding_dimension':25,\n",
    "                      'character_lstm_hidden_state_dimension':25,\n",
    "                      'check_for_digits_replaced_with_zeros':True,\n",
    "                      'check_for_lowercase':True,\n",
    "                      'debug':False,\n",
    "                      'dropout_rate':0.5,\n",
    "                      'experiment_name':'test',\n",
    "                      'freeze_token_embeddings':False,\n",
    "                      'gradient_clipping_value':5.0,\n",
    "                      'learning_rate':0.005,\n",
    "                      'load_only_pretrained_token_embeddings':False,\n",
    "                      'load_all_pretrained_token_embeddings':False,\n",
    "                      'main_evaluation_mode':'conll',\n",
    "                      'maximum_number_of_epochs':500,\n",
    "                      'number_of_cpu_threads':8,\n",
    "                      'number_of_gpus':0,\n",
    "                      'optimizer':'sgd',\n",
    "                      'output_folder':'../../../ML_EntityData/output',\n",
    "                      'patience':10,\n",
    "                      'plot_format':'pdf',\n",
    "                      'reload_character_embeddings':True,\n",
    "                      'reload_character_lstm':True,\n",
    "                      'reload_crf':True,\n",
    "                      'reload_feedforward':True,\n",
    "                      'reload_token_embeddings':True,\n",
    "                      'reload_token_lstm':True,\n",
    "                      'remap_unknown_tokens_to_unk':True,\n",
    "                      'spacylanguage':'en',\n",
    "                      'tagging_format':'bioes',\n",
    "                      'token_embedding_dimension':100,\n",
    "                      'token_lstm_hidden_state_dimension':100,\n",
    "                      'token_pretrained_embedding_filepath':'../../../ML_EntityData/embedding/en/glove.6B.100d.txt',\n",
    "                      'tokenizer':'spacy',\n",
    "                      'train_model':True,\n",
    "                      'use_character_lstm':True,\n",
    "                      'use_crf':True,\n",
    "                      'use_pretrained_model':False,\n",
    "                      'verbose':False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the validity of BRAT-formatted train set... Done.\n",
      "Checking compatibility between CONLL and BRAT for train_compatible_with_brat set ... Done.\n",
      "Checking validity of CONLL BIOES format... Done.\n",
      "Checking the validity of BRAT-formatted valid set... Done.\n",
      "Checking compatibility between CONLL and BRAT for valid_compatible_with_brat set ... Done.\n",
      "Checking validity of CONLL BIOES format... Done.\n",
      "Checking the validity of BRAT-formatted test set... Done.\n",
      "Checking compatibility between CONLL and BRAT for test_compatible_with_brat set ... Done.\n",
      "Checking validity of CONLL BIOES format... Done.\n",
      "Load dataset... done (55.48 seconds)\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "import dataset as ds\n",
    "# Load dataset\n",
    "dataset_filepaths, dataset_brat_folders = utils.get_valid_dataset_filepaths(parameters)\n",
    "dataset = ds.Dataset(verbose=False, debug=False)\n",
    "token_to_vector = dataset.load_dataset(dataset_filepaths, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedded_characters: Tensor(\"character_embedding/embedded_characters:0\", shape=(?, ?, 25), dtype=float32)\n",
      "embedded_tokens: Tensor(\"token_embedding/embedding_lookup:0\", shape=(?, 100), dtype=float32)\n",
      "token_lstm_input: Tensor(\"concatenate_token_and_character_vectors/token_lstm_input:0\", shape=(?, 150), dtype=float32)\n",
      "token_lstm_input_drop: Tensor(\"dropout/token_lstm_input_drop/mul:0\", shape=(?, 150), dtype=float32)\n",
      "token_lstm_input_drop_expanded: Tensor(\"dropout/token_lstm_input_drop_expanded:0\", shape=(1, ?, 150), dtype=float32)\n",
      "unary_scores_expanded: Tensor(\"crf/unary_scores_expanded:0\", shape=(1, ?, 19), dtype=float32)\n",
      "input_label_indices_flat_batch: Tensor(\"crf/input_label_indices_flat_batch:0\", shape=(1, ?), dtype=int32)\n",
      "sequence_lengths: Tensor(\"crf/sequence_lengths:0\", shape=(1,), dtype=int32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:96: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from BLSTM_CRF import Char_BLSTM_CRF\n",
    "# Create model lstm+crf\n",
    "session_conf = tf.ConfigProto(\n",
    "            intra_op_parallelism_threads=parameters['number_of_cpu_threads'],\n",
    "            inter_op_parallelism_threads=parameters['number_of_cpu_threads'],\n",
    "            device_count={'CPU': 1, 'GPU': parameters['number_of_gpus']},\n",
    "            allow_soft_placement=True,\n",
    "            # automatically choose an existing and supported device to run the operations in case the specified one doesn't exist\n",
    "            log_device_placement=False\n",
    "        )\n",
    "sess = tf.Session(config=session_conf)\n",
    "\n",
    "with sess.as_default():\n",
    "    # Create model and initialize or load pretrained model\n",
    "    ### Instantiate the model\n",
    "    model = Char_BLSTM_CRF(dataset=dataset, token_embedding_dimension=parameters['token_embedding_dimension'],\n",
    "                       character_lstm_hidden_state_dimension=parameters['character_lstm_hidden_state_dimension'],\n",
    "                       token_lstm_hidden_state_dimension=parameters['token_lstm_hidden_state_dimension'],\n",
    "                       character_embedding_dimension=parameters['character_embedding_dimension'],\n",
    "                       gradient_clipping_value=parameters['gradient_clipping_value'],\n",
    "                       learning_rate=parameters['learning_rate'],\n",
    "                       freeze_token_embeddings=parameters['freeze_token_embeddings'],\n",
    "                       optimizer=parameters['optimizer'],\n",
    "                       maximum_number_of_epochs=parameters['maximum_number_of_epochs'])\n",
    "\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load token embeddings... done (0.19 seconds)\n",
      "number_of_token_original_case_found: 14618\n",
      "number_of_token_lowercase_found: 11723\n",
      "number_of_token_digits_replaced_with_zeros_found: 119\n",
      "number_of_token_lowercase_and_digits_replaced_with_zeros_found: 16\n",
      "number_of_loaded_word_vectors: 26476\n",
      "dataset.vocabulary_size: 28984\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "model.load_pretrained_token_embeddings(sess, dataset,embedding_filepath=parameters['token_pretrained_embedding_filepath'],\n",
    "                                                       check_lowercase= parameters['check_for_lowercase'],check_digits=parameters['check_for_digits_replaced_with_zeros'],\n",
    "                                                       token_to_vector=token_to_vector)\n",
    "# Initial params_train\n",
    "transition_params_trained = np.random.rand(len(dataset.unique_labels) + 2,len(dataset.unique_labels) + 2)\n",
    "\n",
    "del token_to_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "import os\n",
    "import pickle\n",
    "stats_graph_folder, experiment_timestamp = utils.create_stats_graph_folder(parameters)\n",
    "\n",
    "        # Initialize and save execution details\n",
    "start_time = time.time()\n",
    "# results = {}\n",
    "# results['epoch'] = {}\n",
    "# results['execution_details'] = {}\n",
    "# results['execution_details']['train_start'] = start_time\n",
    "# results['execution_details']['time_stamp'] = experiment_timestamp\n",
    "# results['execution_details']['early_stop'] = False\n",
    "# results['execution_details']['keyboard_interrupt'] = False\n",
    "# results['execution_details']['num_epochs'] = 0\n",
    "# results['model_options'] = copy.copy(parameters)\n",
    "\n",
    "model_folder = os.path.join(stats_graph_folder, 'model')\n",
    "utils.create_folder_if_not_exists(model_folder)\n",
    "\n",
    "pickle.dump(dataset, open(os.path.join(model_folder, 'dataset.pickle'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting epoch 0\n",
      "Training completed in 0.00 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.0025    0.0317    0.0046      1041\n",
      "     B-MISC     0.0020    0.1503    0.0040       858\n",
      "      B-ORG     0.0132    0.0004    0.0008      2485\n",
      "      B-PER     0.0064    0.0049    0.0056      4284\n",
      "      E-LOC     0.0066    0.0029    0.0040      1041\n",
      "     E-MISC     0.0000    0.0000    0.0000       858\n",
      "      E-ORG     0.0000    0.0000    0.0000      2485\n",
      "      E-PER     0.0353    0.0299    0.0323      4284\n",
      "      I-LOC     0.0000    0.0000    0.0000       116\n",
      "     I-MISC     0.0182    0.0034    0.0057       297\n",
      "      I-ORG     0.0021    0.0033    0.0026      1219\n",
      "      I-PER     0.0002    0.0041    0.0003       244\n",
      "          O     0.0000    0.0000    0.0000    163169\n",
      "      S-LOC     0.0075    0.0021    0.0033      6099\n",
      "     S-MISC     0.0108    0.0023    0.0038      2580\n",
      "      S-ORG     0.0102    0.2487    0.0196      3836\n",
      "      S-PER     0.0177    0.0086    0.0116      2316\n",
      "\n",
      "avg / total     0.0019    0.0067    0.0016    197212\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.0033    0.0427    0.0062       234\n",
      "     B-MISC     0.0036    0.2257    0.0070       257\n",
      "      B-ORG     0.0000    0.0000    0.0000       450\n",
      "      B-PER     0.0060    0.0041    0.0048      1234\n",
      "      E-LOC     0.0101    0.0043    0.0060       234\n",
      "     E-MISC     0.0000    0.0000    0.0000       257\n",
      "      E-ORG     0.0000    0.0000    0.0000       450\n",
      "      E-PER     0.0267    0.0186    0.0220      1234\n",
      "      I-LOC     0.0000    0.0000    0.0000        23\n",
      "     I-MISC     0.0000    0.0000    0.0000        89\n",
      "      I-ORG     0.0000    0.0000    0.0000       301\n",
      "      I-PER     0.0007    0.0137    0.0014        73\n",
      "          O     0.0000    0.0000    0.0000     41472\n",
      "      S-LOC     0.0166    0.0044    0.0069      1603\n",
      "     S-MISC     0.0000    0.0000    0.0000       665\n",
      "      S-ORG     0.0115    0.3210    0.0222       891\n",
      "      S-PER     0.0241    0.0115    0.0156       608\n",
      "\n",
      "avg / total     0.0019    0.0079    0.0016     50075\n",
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.0033    0.0474    0.0062       232\n",
      "     B-MISC     0.0008    0.0678    0.0015       177\n",
      "      B-ORG     0.0000    0.0000    0.0000       579\n",
      "      B-PER     0.0109    0.0064    0.0081      1086\n",
      "      E-LOC     0.0108    0.0043    0.0062       232\n",
      "     E-MISC     0.0000    0.0000    0.0000       177\n",
      "      E-ORG     0.0000    0.0000    0.0000       579\n",
      "      E-PER     0.0383    0.0285    0.0327      1086\n",
      "      I-LOC     0.0009    0.0400    0.0017        25\n",
      "     I-MISC     0.0000    0.0000    0.0000        39\n",
      "      I-ORG     0.0000    0.0000    0.0000       256\n",
      "      I-PER     0.0000    0.0000    0.0000        70\n",
      "          O     0.0000    0.0000    0.0000     36433\n",
      "      S-LOC     0.0053    0.0014    0.0022      1436\n",
      "     S-MISC     0.0169    0.0019    0.0034       525\n",
      "      S-ORG     0.0113    0.2024    0.0214      1082\n",
      "      S-PER     0.0178    0.0075    0.0106       531\n",
      "\n",
      "avg / total     0.0021    0.0065    0.0018     44545\n",
      "\n",
      "\n",
      "Starting epoch 1\n",
      "Training completed in 504.92 seconds\n",
      "Evaluate model on the train set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.8180    0.6388    0.7174      1041\n",
      "     B-MISC     0.7781    0.3473    0.4803       858\n",
      "      B-ORG     0.8572    0.5557    0.6743      2485\n",
      "      B-PER     0.9355    0.9307    0.9331      4284\n",
      "      E-LOC     0.8136    0.6330    0.7120      1041\n",
      "     E-MISC     0.7401    0.3252    0.4518       858\n",
      "      E-ORG     0.8717    0.5658    0.6862      2485\n",
      "      E-PER     0.9452    0.9381    0.9417      4284\n",
      "      I-LOC     0.0000    0.0000    0.0000       116\n",
      "     I-MISC     0.0000    0.0000    0.0000       297\n",
      "      I-ORG     0.8228    0.3733    0.5135      1219\n",
      "      I-PER     0.8000    0.3115    0.4484       244\n",
      "          O     0.0000    0.0000    0.0000       335\n",
      "      S-LOC     0.8895    0.9003    0.8949      6099\n",
      "     S-MISC     0.8696    0.6279    0.7292      2580\n",
      "      S-ORG     0.9039    0.6794    0.7757      3836\n",
      "      S-PER     0.9092    0.7008    0.7915      2316\n",
      "\n",
      "avg / total     0.8667    0.7146    0.7733     34378\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.7709    0.5897    0.6683       234\n",
      "     B-MISC     0.7385    0.3735    0.4961       257\n",
      "      B-ORG     0.7967    0.4356    0.5632       450\n",
      "      B-PER     0.9532    0.9408    0.9470      1234\n",
      "      E-LOC     0.7797    0.5897    0.6715       234\n",
      "     E-MISC     0.6984    0.3424    0.4595       257\n",
      "      E-ORG     0.8105    0.4467    0.5759       450\n",
      "      E-PER     0.9627    0.9425    0.9525      1234\n",
      "      I-LOC     0.0000    0.0000    0.0000        23\n",
      "     I-MISC     0.0000    0.0000    0.0000        89\n",
      "      I-ORG     0.8120    0.3588    0.4977       301\n",
      "      I-PER     0.9688    0.4247    0.5905        73\n",
      "          O     0.0000    0.0000    0.0000        88\n",
      "      S-LOC     0.8949    0.9239    0.9091      1603\n",
      "     S-MISC     0.9149    0.6947    0.7897       665\n",
      "      S-ORG     0.8978    0.7194    0.7988       891\n",
      "      S-PER     0.8974    0.7484    0.8161       608\n",
      "\n",
      "avg / total     0.8656    0.7317    0.7823      8691\n",
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.6974    0.5862    0.6370       232\n",
      "     B-MISC     0.6667    0.4520    0.5387       177\n",
      "      B-ORG     0.7959    0.5320    0.6377       579\n",
      "      B-PER     0.9256    0.9273    0.9264      1086\n",
      "      E-LOC     0.6872    0.5776    0.6276       232\n",
      "     E-MISC     0.6695    0.4463    0.5356       177\n",
      "      E-ORG     0.8247    0.5527    0.6618       579\n",
      "      E-PER     0.9410    0.9401    0.9406      1086\n",
      "      I-LOC     0.0000    0.0000    0.0000        25\n",
      "     I-MISC     0.0000    0.0000    0.0000        39\n",
      "      I-ORG     0.7131    0.3398    0.4603       256\n",
      "      I-PER     0.9286    0.1857    0.3095        70\n",
      "          O     0.0000    0.0000    0.0000       168\n",
      "      S-LOC     0.8529    0.8962    0.8740      1436\n",
      "     S-MISC     0.8520    0.6362    0.7285       525\n",
      "      S-ORG     0.8602    0.6368    0.7318      1082\n",
      "      S-PER     0.8994    0.6064    0.7244       531\n",
      "\n",
      "avg / total     0.8274    0.7025    0.7509      8280\n",
      "\n",
      "\n",
      "Starting epoch 2\n",
      "Training completed in 475.27 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9129    0.8156    0.8615      1041\n",
      "     B-MISC     0.7796    0.7214    0.7494       858\n",
      "      B-ORG     0.8533    0.8543    0.8538      2485\n",
      "      B-PER     0.9465    0.9785    0.9622      4284\n",
      "      E-LOC     0.9195    0.8232    0.8687      1041\n",
      "     E-MISC     0.7867    0.7308    0.7577       858\n",
      "      E-ORG     0.8556    0.8563    0.8560      2485\n",
      "      E-PER     0.9522    0.9851    0.9683      4284\n",
      "      I-LOC     1.0000    0.0086    0.0171       116\n",
      "     I-MISC     0.8284    0.3737    0.5151       297\n",
      "      I-ORG     0.7352    0.8540    0.7901      1219\n",
      "      I-PER     0.8471    0.8402    0.8436       244\n",
      "          O     0.0000    0.0000    0.0000       648\n",
      "      S-LOC     0.9501    0.9397    0.9449      6099\n",
      "     S-MISC     0.9416    0.8194    0.8763      2580\n",
      "      S-ORG     0.8837    0.8736    0.8786      3836\n",
      "      S-PER     0.9110    0.8882    0.8994      2316\n",
      "\n",
      "avg / total     0.8884    0.8713    0.8767     34691\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9133    0.7650    0.8326       234\n",
      "     B-MISC     0.7321    0.6381    0.6819       257\n",
      "      B-ORG     0.8027    0.8044    0.8036       450\n",
      "      B-PER     0.9665    0.9822    0.9743      1234\n",
      "      E-LOC     0.9040    0.7650    0.8287       234\n",
      "     E-MISC     0.7739    0.6926    0.7310       257\n",
      "      E-ORG     0.8013    0.8067    0.8040       450\n",
      "      E-PER     0.9704    0.9846    0.9775      1234\n",
      "      I-LOC     1.0000    0.0435    0.0833        23\n",
      "     I-MISC     0.6667    0.2921    0.4062        89\n",
      "      I-ORG     0.7687    0.7841    0.7763       301\n",
      "      I-PER     0.8667    0.7123    0.7820        73\n",
      "          O     0.0000    0.0000    0.0000       145\n",
      "      S-LOC     0.9392    0.9545    0.9468      1603\n",
      "     S-MISC     0.9444    0.8421    0.8903       665\n",
      "      S-ORG     0.8940    0.8900    0.8920       891\n",
      "      S-PER     0.8821    0.8980    0.8900       608\n",
      "\n",
      "avg / total     0.8879    0.8683    0.8754      8748\n",
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.7964    0.7586    0.7770       232\n",
      "     B-MISC     0.5678    0.6384    0.6011       177\n",
      "      B-ORG     0.7933    0.8152    0.8041       579\n",
      "      B-PER     0.9570    0.9843    0.9705      1086\n",
      "      E-LOC     0.7778    0.7543    0.7659       232\n",
      "     E-MISC     0.5678    0.6384    0.6011       177\n",
      "      E-ORG     0.7953    0.8187    0.8068       579\n",
      "      E-PER     0.9630    0.9834    0.9731      1086\n",
      "      I-LOC     0.0000    0.0000    0.0000        25\n",
      "     I-MISC     0.5600    0.3590    0.4375        39\n",
      "      I-ORG     0.7226    0.8750    0.7915       256\n",
      "      I-PER     0.9048    0.8143    0.8571        70\n",
      "          O     0.0000    0.0000    0.0000       291\n",
      "      S-LOC     0.9024    0.9276    0.9148      1436\n",
      "     S-MISC     0.8936    0.7676    0.8258       525\n",
      "      S-ORG     0.8892    0.8530    0.8708      1082\n",
      "      S-PER     0.9237    0.8211    0.8694       531\n",
      "\n",
      "avg / total     0.8401    0.8389    0.8384      8403\n",
      "\n",
      "\n",
      "Starting epoch 3\n",
      "Training completed in 474.12 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.8997    0.8444    0.8712      1041\n",
      "     B-MISC     0.8720    0.6830    0.7660       858\n",
      "      B-ORG     0.8472    0.8833    0.8649      2485\n",
      "      B-PER     0.9666    0.9795    0.9730      4284\n",
      "      E-LOC     0.8994    0.8501    0.8741      1041\n",
      "     E-MISC     0.8996    0.6993    0.7869       858\n",
      "      E-ORG     0.8456    0.8813    0.8631      2485\n",
      "      E-PER     0.9712    0.9834    0.9773      4284\n",
      "      I-LOC     0.9167    0.1897    0.3143       116\n",
      "     I-MISC     0.8523    0.5051    0.6342       297\n",
      "      I-ORG     0.7866    0.8409    0.8128      1219\n",
      "      I-PER     0.9318    0.8402    0.8836       244\n",
      "          O     0.0000    0.0000    0.0000       512\n",
      "      S-LOC     0.9314    0.9633    0.9470      6099\n",
      "     S-MISC     0.9230    0.8601    0.8904      2580\n",
      "      S-ORG     0.9301    0.8676    0.8978      3836\n",
      "      S-PER     0.9159    0.9128    0.9144      2316\n",
      "\n",
      "avg / total     0.9028    0.8879    0.8932     34555\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9146    0.7778    0.8406       234\n",
      "     B-MISC     0.7970    0.6109    0.6916       257\n",
      "      B-ORG     0.7911    0.8333    0.8117       450\n",
      "      B-PER     0.9750    0.9806    0.9778      1234\n",
      "      E-LOC     0.9192    0.7778    0.8426       234\n",
      "     E-MISC     0.8600    0.6693    0.7527       257\n",
      "      E-ORG     0.7832    0.8267    0.8043       450\n",
      "      E-PER     0.9766    0.9797    0.9782      1234\n",
      "      I-LOC     0.6667    0.0870    0.1538        23\n",
      "     I-MISC     0.7083    0.3820    0.4964        89\n",
      "      I-ORG     0.8316    0.7874    0.8089       301\n",
      "      I-PER     0.9423    0.6712    0.7840        73\n",
      "          O     0.0000    0.0000    0.0000       111\n",
      "      S-LOC     0.9357    0.9707    0.9528      1603\n",
      "     S-MISC     0.9115    0.8827    0.8969       665\n",
      "      S-ORG     0.9292    0.8979    0.9132       891\n",
      "      S-PER     0.8817    0.9194    0.9002       608\n",
      "\n",
      "avg / total     0.8996    0.8817    0.8881      8714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.8018    0.7672    0.7841       232\n",
      "     B-MISC     0.6066    0.6271    0.6167       177\n",
      "      B-ORG     0.8000    0.8428    0.8209       579\n",
      "      B-PER     0.9692    0.9853    0.9772      1086\n",
      "      E-LOC     0.8053    0.7845    0.7948       232\n",
      "     E-MISC     0.6484    0.6667    0.6574       177\n",
      "      E-ORG     0.8062    0.8480    0.8266       579\n",
      "      E-PER     0.9753    0.9825    0.9789      1086\n",
      "      I-LOC     0.7500    0.1200    0.2069        25\n",
      "     I-MISC     0.5714    0.5128    0.5405        39\n",
      "      I-ORG     0.7390    0.8516    0.7913       256\n",
      "      I-PER     0.9833    0.8429    0.9077        70\n",
      "          O     0.0000    0.0000    0.0000       257\n",
      "      S-LOC     0.8979    0.9366    0.9168      1436\n",
      "     S-MISC     0.8760    0.8076    0.8404       525\n",
      "      S-ORG     0.9137    0.8420    0.8764      1082\n",
      "      S-PER     0.9163    0.8456    0.8795       531\n",
      "\n",
      "avg / total     0.8556    0.8524    0.8526      8369\n",
      "\n",
      "\n",
      "Starting epoch 4\n",
      "Training completed in 486.12 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.8272    0.9011    0.8625      1041\n",
      "     B-MISC     0.9071    0.6375    0.7488       858\n",
      "      B-ORG     0.8730    0.8797    0.8763      2485\n",
      "      B-PER     0.9687    0.9837    0.9761      4284\n",
      "      E-LOC     0.8362    0.9020    0.8678      1041\n",
      "     E-MISC     0.9342    0.6620    0.7749       858\n",
      "      E-ORG     0.8702    0.8797    0.8749      2485\n",
      "      E-PER     0.9724    0.9867    0.9795      4284\n",
      "      I-LOC     0.8269    0.3707    0.5119       116\n",
      "     I-MISC     0.8476    0.4680    0.6030       297\n",
      "      I-ORG     0.8521    0.8080    0.8295      1219\n",
      "      I-PER     0.9095    0.9057    0.9076       244\n",
      "          O     0.0000    0.0000    0.0000       482\n",
      "      S-LOC     0.9472    0.9647    0.9559      6099\n",
      "     S-MISC     0.9211    0.8733    0.8965      2580\n",
      "      S-ORG     0.9018    0.9054    0.9036      3836\n",
      "      S-PER     0.9371    0.9141    0.9255      2316\n",
      "\n",
      "avg / total     0.9081    0.8956    0.8997     34525\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.7977    0.8761    0.8350       234\n",
      "     B-MISC     0.8400    0.5720    0.6806       257\n",
      "      B-ORG     0.8107    0.8089    0.8098       450\n",
      "      B-PER     0.9854    0.9830    0.9842      1234\n",
      "      E-LOC     0.8056    0.8675    0.8354       234\n",
      "     E-MISC     0.9056    0.6342    0.7460       257\n",
      "      E-ORG     0.8067    0.8067    0.8067       450\n",
      "      E-PER     0.9854    0.9838    0.9846      1234\n",
      "      I-LOC     0.6667    0.4348    0.5263        23\n",
      "     I-MISC     0.7568    0.3146    0.4444        89\n",
      "      I-ORG     0.8934    0.7243    0.8000       301\n",
      "      I-PER     0.9444    0.6986    0.8031        73\n",
      "          O     0.0000    0.0000    0.0000       106\n",
      "      S-LOC     0.9368    0.9707    0.9534      1603\n",
      "     S-MISC     0.9196    0.8767    0.8976       665\n",
      "      S-ORG     0.9003    0.9226    0.9113       891\n",
      "      S-PER     0.9072    0.9161    0.9116       608\n",
      "\n",
      "avg / total     0.9038    0.8838    0.8907      8709\n",
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.6809    0.8276    0.7471       232\n",
      "     B-MISC     0.6818    0.5932    0.6344       177\n",
      "      B-ORG     0.8099    0.7876    0.7986       579\n",
      "      B-PER     0.9736    0.9843    0.9789      1086\n",
      "      E-LOC     0.6844    0.8319    0.7510       232\n",
      "     E-MISC     0.7143    0.6215    0.6647       177\n",
      "      E-ORG     0.8254    0.8083    0.8168       579\n",
      "      E-PER     0.9761    0.9797    0.9779      1086\n",
      "      I-LOC     0.5833    0.2800    0.3784        25\n",
      "     I-MISC     0.7333    0.5641    0.6377        39\n",
      "      I-ORG     0.8050    0.7578    0.7807       256\n",
      "      I-PER     0.9254    0.8857    0.9051        70\n",
      "          O     0.0000    0.0000    0.0000       256\n",
      "      S-LOC     0.8973    0.9373    0.9169      1436\n",
      "     S-MISC     0.8591    0.8362    0.8475       525\n",
      "      S-ORG     0.8829    0.8780    0.8804      1082\n",
      "      S-PER     0.9419    0.8249    0.8795       531\n",
      "\n",
      "avg / total     0.8529    0.8503    0.8505      8368\n",
      "\n",
      "\n",
      "Starting epoch 5\n",
      "Training completed in 481.25 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9770    0.8146    0.8884      1041\n",
      "     B-MISC     0.8903    0.7949    0.8399       858\n",
      "      B-ORG     0.8498    0.9360    0.8908      2485\n",
      "      B-PER     0.9635    0.9869    0.9751      4284\n",
      "      E-LOC     0.9770    0.8175    0.8902      1041\n",
      "     E-MISC     0.8969    0.8007    0.8461       858\n",
      "      E-ORG     0.8534    0.9392    0.8943      2485\n",
      "      E-PER     0.9674    0.9911    0.9791      4284\n",
      "      I-LOC     0.8444    0.3276    0.4720       116\n",
      "     I-MISC     0.8615    0.6700    0.7538       297\n",
      "      I-ORG     0.8321    0.8942    0.8620      1219\n",
      "      I-PER     0.8711    0.9139    0.8920       244\n",
      "          O     0.0000    0.0000    0.0000       469\n",
      "      S-LOC     0.9757    0.9498    0.9626      6099\n",
      "     S-MISC     0.9754    0.8461    0.9062      2580\n",
      "      S-ORG     0.9168    0.9215    0.9191      3836\n",
      "      S-PER     0.9052    0.9400    0.9223      2316\n",
      "\n",
      "avg / total     0.9195    0.9110    0.9134     34512\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9778    0.7521    0.8502       234\n",
      "     B-MISC     0.8341    0.6848    0.7521       257\n",
      "      B-ORG     0.7466    0.8644    0.8012       450\n",
      "      B-PER     0.9712    0.9854    0.9783      1234\n",
      "      E-LOC     0.9721    0.7436    0.8426       234\n",
      "     E-MISC     0.8638    0.7160    0.7830       257\n",
      "      E-ORG     0.7620    0.8822    0.8177       450\n",
      "      E-PER     0.9744    0.9870    0.9807      1234\n",
      "      I-LOC     1.0000    0.3043    0.4667        23\n",
      "     I-MISC     0.8036    0.5056    0.6207        89\n",
      "      I-ORG     0.8249    0.8140    0.8194       301\n",
      "      I-PER     0.9138    0.7260    0.8092        73\n",
      "          O     0.0000    0.0000    0.0000       125\n",
      "      S-LOC     0.9612    0.9582    0.9597      1603\n",
      "     S-MISC     0.9691    0.8496    0.9054       665\n",
      "      S-ORG     0.8907    0.9416    0.9154       891\n",
      "      S-PER     0.8975    0.9359    0.9163       608\n",
      "\n",
      "avg / total     0.9059    0.8924    0.8961      8728\n",
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.8836    0.7198    0.7933       232\n",
      "     B-MISC     0.5969    0.6441    0.6196       177\n",
      "      B-ORG     0.7751    0.8808    0.8246       579\n",
      "      B-PER     0.9729    0.9908    0.9818      1086\n",
      "      E-LOC     0.8836    0.7198    0.7933       232\n",
      "     E-MISC     0.6316    0.6780    0.6540       177\n",
      "      E-ORG     0.7781    0.8843    0.8278       579\n",
      "      E-PER     0.9737    0.9890    0.9813      1086\n",
      "      I-LOC     0.5833    0.2800    0.3784        25\n",
      "     I-MISC     0.6765    0.5897    0.6301        39\n",
      "      I-ORG     0.7282    0.8789    0.7965       256\n",
      "      I-PER     0.9559    0.9286    0.9420        70\n",
      "          O     0.0000    0.0000    0.0000       298\n",
      "      S-LOC     0.9407    0.9283    0.9345      1436\n",
      "     S-MISC     0.8987    0.7771    0.8335       525\n",
      "      S-ORG     0.8765    0.8983    0.8873      1082\n",
      "      S-PER     0.9096    0.8719    0.8904       531\n",
      "\n",
      "avg / total     0.8548    0.8604    0.8559      8410\n",
      "\n",
      "\n",
      "Starting epoch 6\n",
      "Training completed in 454.05 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9398    0.8847    0.9114      1041\n",
      "     B-MISC     0.9344    0.7308    0.8201       858\n",
      "      B-ORG     0.8968    0.9123    0.9044      2485\n",
      "      B-PER     0.9575    0.9895    0.9733      4284\n",
      "      E-LOC     0.9418    0.8857    0.9129      1041\n",
      "     E-MISC     0.9463    0.7401    0.8306       858\n",
      "      E-ORG     0.8963    0.9115    0.9038      2485\n",
      "      E-PER     0.9629    0.9937    0.9781      4284\n",
      "      I-LOC     0.9062    0.5000    0.6444       116\n",
      "     I-MISC     0.9005    0.5791    0.7049       297\n",
      "      I-ORG     0.7530    0.9401    0.8362      1219\n",
      "      I-PER     0.8858    0.9221    0.9036       244\n",
      "          O     0.0000    0.0000    0.0000       558\n",
      "      S-LOC     0.9630    0.9692    0.9661      6099\n",
      "     S-MISC     0.9201    0.9062    0.9131      2580\n",
      "      S-ORG     0.9646    0.8887    0.9251      3836\n",
      "      S-PER     0.8726    0.9581    0.9134      2316\n",
      "\n",
      "avg / total     0.9170    0.9136    0.9134     34601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9434    0.8547    0.8969       234\n",
      "     B-MISC     0.8542    0.6381    0.7305       257\n",
      "      B-ORG     0.7891    0.8400    0.8138       450\n",
      "      B-PER     0.9689    0.9862    0.9775      1234\n",
      "      E-LOC     0.9384    0.8462    0.8899       234\n",
      "     E-MISC     0.9119    0.6848    0.7822       257\n",
      "      E-ORG     0.8063    0.8600    0.8323       450\n",
      "      E-PER     0.9697    0.9862    0.9779      1234\n",
      "      I-LOC     0.8000    0.5217    0.6316        23\n",
      "     I-MISC     0.8571    0.4719    0.6087        89\n",
      "      I-ORG     0.7166    0.8738    0.7874       301\n",
      "      I-PER     0.9298    0.7260    0.8154        73\n",
      "          O     0.0000    0.0000    0.0000       169\n",
      "      S-LOC     0.9524    0.9744    0.9633      1603\n",
      "     S-MISC     0.9183    0.8962    0.9072       665\n",
      "      S-ORG     0.9427    0.8866    0.9138       891\n",
      "      S-PER     0.8343    0.9523    0.8894       608\n",
      "\n",
      "avg / total     0.8969    0.8931    0.8924      8772\n",
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.7966    0.8103    0.8034       232\n",
      "     B-MISC     0.6810    0.6271    0.6529       177\n",
      "      B-ORG     0.8095    0.8515    0.8300       579\n",
      "      B-PER     0.9729    0.9908    0.9818      1086\n",
      "      E-LOC     0.7924    0.8060    0.7991       232\n",
      "     E-MISC     0.7117    0.6554    0.6824       177\n",
      "      E-ORG     0.8062    0.8480    0.8266       579\n",
      "      E-PER     0.9737    0.9890    0.9813      1086\n",
      "      I-LOC     0.5625    0.3600    0.4390        25\n",
      "     I-MISC     0.7778    0.5385    0.6364        39\n",
      "      I-ORG     0.6492    0.9180    0.7605       256\n",
      "      I-PER     0.9565    0.9429    0.9496        70\n",
      "          O     0.0000    0.0000    0.0000       329\n",
      "      S-LOC     0.9168    0.9359    0.9263      1436\n",
      "     S-MISC     0.8252    0.8362    0.8307       525\n",
      "      S-ORG     0.9260    0.8558    0.8895      1082\n",
      "      S-PER     0.8822    0.8889    0.8856       531\n",
      "\n",
      "avg / total     0.8485    0.8587    0.8524      8441\n",
      "\n",
      "\n",
      "Starting epoch 7\n",
      "Training completed in 457.83 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9413    0.8934    0.9167      1041\n",
      "     B-MISC     0.8733    0.8834    0.8783       858\n",
      "      B-ORG     0.9340    0.9223    0.9281      2485\n",
      "      B-PER     0.9740    0.9883    0.9811      4284\n",
      "      E-LOC     0.9414    0.8943    0.9172      1041\n",
      "     E-MISC     0.8694    0.8846    0.8769       858\n",
      "      E-ORG     0.9336    0.9223    0.9279      2485\n",
      "      E-PER     0.9779    0.9918    0.9848      4284\n",
      "      I-LOC     0.8387    0.4483    0.5843       116\n",
      "     I-MISC     0.8366    0.7239    0.7762       297\n",
      "      I-ORG     0.9009    0.8728    0.8867      1219\n",
      "      I-PER     0.9109    0.9221    0.9165       244\n",
      "          O     0.0000    0.0000    0.0000       314\n",
      "      S-LOC     0.9789    0.9600    0.9694      6099\n",
      "     S-MISC     0.9250    0.9178    0.9214      2580\n",
      "      S-ORG     0.9639    0.9111    0.9367      3836\n",
      "      S-PER     0.9338    0.9560    0.9447      2316\n",
      "\n",
      "avg / total     0.9413    0.9294    0.9350     34357\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9312    0.8675    0.8982       234\n",
      "     B-MISC     0.7661    0.7393    0.7525       257\n",
      "      B-ORG     0.8319    0.8356    0.8337       450\n",
      "      B-PER     0.9846    0.9854    0.9850      1234\n",
      "      E-LOC     0.9393    0.8590    0.8973       234\n",
      "     E-MISC     0.7945    0.7821    0.7882       257\n",
      "      E-ORG     0.8473    0.8511    0.8492       450\n",
      "      E-PER     0.9830    0.9838    0.9834      1234\n",
      "      I-LOC     0.9091    0.4348    0.5882        23\n",
      "     I-MISC     0.6119    0.4607    0.5256        89\n",
      "      I-ORG     0.8927    0.7741    0.8292       301\n",
      "      I-PER     0.9808    0.6986    0.8160        73\n",
      "          O     0.0000    0.0000    0.0000       114\n",
      "      S-LOC     0.9580    0.9669    0.9624      1603\n",
      "     S-MISC     0.9149    0.9053    0.9101       665\n",
      "      S-ORG     0.9323    0.9113    0.9217       891\n",
      "      S-PER     0.8844    0.9309    0.9071       608\n",
      "\n",
      "avg / total     0.9121    0.9004    0.9054      8717\n",
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.7569    0.8319    0.7926       232\n",
      "     B-MISC     0.6041    0.6723    0.6364       177\n",
      "      B-ORG     0.8357    0.8256    0.8306       579\n",
      "      B-PER     0.9781    0.9890    0.9835      1086\n",
      "      E-LOC     0.7659    0.8319    0.7975       232\n",
      "     E-MISC     0.6350    0.7175    0.6737       177\n",
      "      E-ORG     0.8494    0.8377    0.8435       579\n",
      "      E-PER     0.9790    0.9880    0.9835      1086\n",
      "      I-LOC     0.4815    0.5200    0.5000        25\n",
      "     I-MISC     0.5946    0.5641    0.5789        39\n",
      "      I-ORG     0.7940    0.8281    0.8107       256\n",
      "      I-PER     0.9552    0.9143    0.9343        70\n",
      "          O     0.0000    0.0000    0.0000       267\n",
      "      S-LOC     0.9311    0.9318    0.9314      1436\n",
      "     S-MISC     0.8340    0.8419    0.8379       525\n",
      "      S-ORG     0.9219    0.8725    0.8965      1082\n",
      "      S-PER     0.9121    0.8795    0.8955       531\n",
      "\n",
      "avg / total     0.8636    0.8645    0.8637      8379\n",
      "\n",
      "\n",
      "Starting epoch 8\n",
      "Training completed in 443.08 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9302    0.9212    0.9257      1041\n",
      "     B-MISC     0.9243    0.8252    0.8719       858\n",
      "      B-ORG     0.9392    0.8954    0.9168      2485\n",
      "      B-PER     0.9747    0.9893    0.9819      4284\n",
      "      E-LOC     0.9265    0.9203    0.9234      1041\n",
      "     E-MISC     0.9269    0.8275    0.8744       858\n",
      "      E-ORG     0.9388    0.8946    0.9161      2485\n",
      "      E-PER     0.9786    0.9928    0.9856      4284\n",
      "      I-LOC     0.9000    0.5431    0.6774       116\n",
      "     I-MISC     0.8894    0.6498    0.7510       297\n",
      "      I-ORG     0.9294    0.8105    0.8659      1219\n",
      "      I-PER     0.9146    0.9221    0.9184       244\n",
      "          O     0.0000    0.0000    0.0000       229\n",
      "      S-LOC     0.9603    0.9761    0.9681      6099\n",
      "     S-MISC     0.9574    0.8977    0.9266      2580\n",
      "      S-ORG     0.9455    0.9320    0.9387      3836\n",
      "      S-PER     0.9520    0.9417    0.9468      2316\n",
      "\n",
      "avg / total     0.9465    0.9269    0.9360     34272\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9182    0.8632    0.8899       234\n",
      "     B-MISC     0.8357    0.6926    0.7574       257\n",
      "      B-ORG     0.8616    0.8022    0.8308       450\n",
      "      B-PER     0.9751    0.9846    0.9798      1234\n",
      "      E-LOC     0.9009    0.8547    0.8772       234\n",
      "     E-MISC     0.8785    0.7315    0.7983       257\n",
      "      E-ORG     0.8687    0.8089    0.8377       450\n",
      "      E-PER     0.9767    0.9846    0.9806      1234\n",
      "      I-LOC     0.6087    0.6087    0.6087        23\n",
      "     I-MISC     0.8200    0.4607    0.5899        89\n",
      "      I-ORG     0.9298    0.7475    0.8287       301\n",
      "      I-PER     0.9455    0.7123    0.8125        73\n",
      "          O     0.0000    0.0000    0.0000        62\n",
      "      S-LOC     0.9438    0.9744    0.9589      1603\n",
      "     S-MISC     0.9467    0.8812    0.9128       665\n",
      "      S-ORG     0.9334    0.9282    0.9308       891\n",
      "      S-PER     0.9080    0.9095    0.9088       608\n",
      "\n",
      "avg / total     0.9250    0.8982    0.9099      8665\n",
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.7769    0.8707    0.8211       232\n",
      "     B-MISC     0.6474    0.6328    0.6400       177\n",
      "      B-ORG     0.8634    0.7858    0.8228       579\n",
      "      B-PER     0.9747    0.9917    0.9831      1086\n",
      "      E-LOC     0.7860    0.8707    0.8262       232\n",
      "     E-MISC     0.6743    0.6667    0.6705       177\n",
      "      E-ORG     0.8745    0.7945    0.8326       579\n",
      "      E-PER     0.9737    0.9899    0.9817      1086\n",
      "      I-LOC     0.5000    0.4800    0.4898        25\n",
      "     I-MISC     0.7143    0.5128    0.5970        39\n",
      "      I-ORG     0.8313    0.7891    0.8096       256\n",
      "      I-PER     0.9565    0.9429    0.9496        70\n",
      "          O     0.0000    0.0000    0.0000       208\n",
      "      S-LOC     0.9061    0.9408    0.9231      1436\n",
      "     S-MISC     0.8864    0.8171    0.8503       525\n",
      "      S-ORG     0.9024    0.8799    0.8910      1082\n",
      "      S-PER     0.9421    0.8588    0.8985       531\n",
      "\n",
      "avg / total     0.8752    0.8641    0.8689      8320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting epoch 9\n",
      "Training completed in 565.00 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9513    0.9193    0.9350      1041\n",
      "     B-MISC     0.9476    0.8217    0.8801       858\n",
      "      B-ORG     0.9155    0.9457    0.9303      2485\n",
      "      B-PER     0.9767    0.9886    0.9826      4284\n",
      "      E-LOC     0.9486    0.9212    0.9347      1041\n",
      "     E-MISC     0.9502    0.8228    0.8819       858\n",
      "      E-ORG     0.9151    0.9453    0.9299      2485\n",
      "      E-PER     0.9795    0.9904    0.9849      4284\n",
      "      I-LOC     0.8387    0.6724    0.7464       116\n",
      "     I-MISC     0.9293    0.6195    0.7434       297\n",
      "      I-ORG     0.9048    0.9048    0.9048      1219\n",
      "      I-PER     0.9120    0.9344    0.9231       244\n",
      "          O     0.0000    0.0000    0.0000       378\n",
      "      S-LOC     0.9757    0.9759    0.9758      6099\n",
      "     S-MISC     0.9466    0.9283    0.9374      2580\n",
      "      S-ORG     0.9552    0.9445    0.9498      3836\n",
      "      S-PER     0.9188    0.9672    0.9424      2316\n",
      "\n",
      "avg / total     0.9418    0.9386    0.9396     34421\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9279    0.8803    0.9035       234\n",
      "     B-MISC     0.8673    0.7121    0.7821       257\n",
      "      B-ORG     0.8157    0.8756    0.8446       450\n",
      "      B-PER     0.9814    0.9838    0.9826      1234\n",
      "      E-LOC     0.9234    0.8761    0.8991       234\n",
      "     E-MISC     0.9009    0.7432    0.8145       257\n",
      "      E-ORG     0.8219    0.8822    0.8510       450\n",
      "      E-PER     0.9798    0.9830    0.9814      1234\n",
      "      I-LOC     0.6538    0.7391    0.6939        23\n",
      "     I-MISC     0.8627    0.4944    0.6286        89\n",
      "      I-ORG     0.8849    0.8173    0.8497       301\n",
      "      I-PER     0.9808    0.6986    0.8160        73\n",
      "          O     0.0000    0.0000    0.0000       123\n",
      "      S-LOC     0.9611    0.9701    0.9655      1603\n",
      "     S-MISC     0.9301    0.9008    0.9152       665\n",
      "      S-ORG     0.9159    0.9416    0.9286       891\n",
      "      S-PER     0.8817    0.9441    0.9118       608\n",
      "\n",
      "avg / total     0.9152    0.9085    0.9104      8726\n",
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.7871    0.8448    0.8150       232\n",
      "     B-MISC     0.6951    0.6441    0.6686       177\n",
      "      B-ORG     0.8000    0.8636    0.8306       579\n",
      "      B-PER     0.9808    0.9862    0.9835      1086\n",
      "      E-LOC     0.7959    0.8405    0.8176       232\n",
      "     E-MISC     0.7212    0.6723    0.6959       177\n",
      "      E-ORG     0.8080    0.8722    0.8389       579\n",
      "      E-PER     0.9798    0.9834    0.9816      1086\n",
      "      I-LOC     0.5200    0.5200    0.5200        25\n",
      "     I-MISC     0.7692    0.5128    0.6154        39\n",
      "      I-ORG     0.7801    0.8594    0.8178       256\n",
      "      I-PER     0.9420    0.9286    0.9353        70\n",
      "          O     0.0000    0.0000    0.0000       297\n",
      "      S-LOC     0.9293    0.9338    0.9316      1436\n",
      "     S-MISC     0.8417    0.8305    0.8360       525\n",
      "      S-ORG     0.8943    0.8919    0.8931      1082\n",
      "      S-PER     0.9152    0.8945    0.9048       531\n",
      "\n",
      "avg / total     0.8582    0.8685    0.8629      8409\n",
      "\n",
      "\n",
      "Starting epoch 10\n",
      "Training completed in 508.99 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9724    0.8799    0.9239      1041\n",
      "     B-MISC     0.9431    0.8695    0.9048       858\n",
      "      B-ORG     0.9387    0.9368    0.9378      2485\n",
      "      B-PER     0.9661    0.9911    0.9785      4284\n",
      "      E-LOC     0.9735    0.8838    0.9265      1041\n",
      "     E-MISC     0.9357    0.8648    0.8988       858\n",
      "      E-ORG     0.9375    0.9360    0.9368      2485\n",
      "      E-PER     0.9709    0.9953    0.9829      4284\n",
      "      I-LOC     0.9508    0.5000    0.6554       116\n",
      "     I-MISC     0.9298    0.7138    0.8076       297\n",
      "      I-ORG     0.8861    0.9253    0.9053      1219\n",
      "      I-PER     0.8694    0.9549    0.9102       244\n",
      "          O     0.0000    0.0000    0.0000       349\n",
      "      S-LOC     0.9811    0.9700    0.9755      6099\n",
      "     S-MISC     0.9479    0.9306    0.9392      2580\n",
      "      S-ORG     0.9454    0.9473    0.9464      3836\n",
      "      S-PER     0.9171    0.9650    0.9405      2316\n",
      "\n",
      "avg / total     0.9437    0.9393    0.9408     34392\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9707    0.8504    0.9066       234\n",
      "     B-MISC     0.8225    0.7393    0.7787       257\n",
      "      B-ORG     0.8565    0.8356    0.8459       450\n",
      "      B-PER     0.9651    0.9870    0.9760      1234\n",
      "      E-LOC     0.9559    0.8333    0.8904       234\n",
      "     E-MISC     0.8621    0.7782    0.8180       257\n",
      "      E-ORG     0.8750    0.8556    0.8652       450\n",
      "      E-PER     0.9675    0.9878    0.9775      1234\n",
      "      I-LOC     0.9231    0.5217    0.6667        23\n",
      "     I-MISC     0.7797    0.5169    0.6216        89\n",
      "      I-ORG     0.8957    0.8272    0.8601       301\n",
      "      I-PER     0.9153    0.7397    0.8182        73\n",
      "          O     0.0000    0.0000    0.0000       123\n",
      "      S-LOC     0.9645    0.9669    0.9657      1603\n",
      "     S-MISC     0.9215    0.9008    0.9110       665\n",
      "      S-ORG     0.9082    0.9327    0.9203       891\n",
      "      S-PER     0.8499    0.9589    0.9011       608\n",
      "\n",
      "avg / total     0.9122    0.9060    0.9079      8726\n",
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.8122    0.8017    0.8069       232\n",
      "     B-MISC     0.6290    0.6610    0.6446       177\n",
      "      B-ORG     0.8436    0.8290    0.8362       579\n",
      "      B-PER     0.9651    0.9945    0.9796      1086\n",
      "      E-LOC     0.8194    0.8017    0.8105       232\n",
      "     E-MISC     0.6471    0.6836    0.6648       177\n",
      "      E-ORG     0.8524    0.8377    0.8449       579\n",
      "      E-PER     0.9642    0.9926    0.9782      1086\n",
      "      I-LOC     0.5000    0.4000    0.4444        25\n",
      "     I-MISC     0.6897    0.5128    0.5882        39\n",
      "      I-ORG     0.7474    0.8438    0.7927       256\n",
      "      I-PER     0.9067    0.9714    0.9379        70\n",
      "          O     0.0000    0.0000    0.0000       310\n",
      "      S-LOC     0.9348    0.9283    0.9315      1436\n",
      "     S-MISC     0.8318    0.8381    0.8349       525\n",
      "      S-ORG     0.8736    0.8946    0.8840      1082\n",
      "      S-PER     0.8791    0.9040    0.8914       531\n",
      "\n",
      "avg / total     0.8510    0.8630    0.8567      8422\n",
      "\n",
      "\n",
      "Starting epoch 11\n",
      "Training completed in 464.30 seconds\n",
      "Evaluate model on the train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9416    0.9452    0.9434      1041\n",
      "     B-MISC     0.9435    0.8951    0.9187       858\n",
      "      B-ORG     0.9691    0.9344    0.9514      2485\n",
      "      B-PER     0.9824    0.9909    0.9866      4284\n",
      "      E-LOC     0.9407    0.9452    0.9430      1041\n",
      "     E-MISC     0.9409    0.8904    0.9150       858\n",
      "      E-ORG     0.9675    0.9332    0.9500      2485\n",
      "      E-PER     0.9847    0.9930    0.9888      4284\n",
      "      I-LOC     0.8190    0.8190    0.8190       116\n",
      "     I-MISC     0.8811    0.8485    0.8645       297\n",
      "      I-ORG     0.9543    0.9089    0.9311      1219\n",
      "      I-PER     0.9426    0.9426    0.9426       244\n",
      "          O     0.0000    0.0000    0.0000       189\n",
      "      S-LOC     0.9758    0.9787    0.9772      6099\n",
      "     S-MISC     0.9609    0.9236    0.9419      2580\n",
      "      S-ORG     0.9710    0.9421    0.9563      3836\n",
      "      S-PER     0.9471    0.9663    0.9566      2316\n",
      "\n",
      "avg / total     0.9615    0.9503    0.9557     34232\n",
      "\n",
      "Evaluate model on the valid set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.9292    0.8974    0.9130       234\n",
      "     B-MISC     0.7937    0.7782    0.7859       257\n",
      "      B-ORG     0.8892    0.8200    0.8532       450\n",
      "      B-PER     0.9806    0.9838    0.9822      1234\n",
      "      E-LOC     0.9204    0.8889    0.9043       234\n",
      "     E-MISC     0.8228    0.8132    0.8180       257\n",
      "      E-ORG     0.9084    0.8378    0.8717       450\n",
      "      E-PER     0.9822    0.9846    0.9834      1234\n",
      "      I-LOC     0.5000    0.5217    0.5106        23\n",
      "     I-MISC     0.6104    0.5281    0.5663        89\n",
      "      I-ORG     0.9084    0.7575    0.8261       301\n",
      "      I-PER     0.9455    0.7123    0.8125        73\n",
      "          O     0.0000    0.0000    0.0000       100\n",
      "      S-LOC     0.9588    0.9732    0.9659      1603\n",
      "     S-MISC     0.9204    0.9038    0.9120       665\n",
      "      S-ORG     0.9286    0.9338    0.9312       891\n",
      "      S-PER     0.8885    0.9309    0.9092       608\n",
      "\n",
      "avg / total     0.9197    0.9077    0.9131      8703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluate model on the test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.7786    0.9095    0.8390       232\n",
      "     B-MISC     0.6178    0.6667    0.6413       177\n",
      "      B-ORG     0.8790    0.8152    0.8459       579\n",
      "      B-PER     0.9783    0.9954    0.9868      1086\n",
      "      E-LOC     0.7786    0.9095    0.8390       232\n",
      "     E-MISC     0.6387    0.6893    0.6630       177\n",
      "      E-ORG     0.8901    0.8256    0.8566       579\n",
      "      E-PER     0.9764    0.9917    0.9840      1086\n",
      "      I-LOC     0.4872    0.7600    0.5938        25\n",
      "     I-MISC     0.5854    0.6154    0.6000        39\n",
      "      I-ORG     0.8167    0.8008    0.8087       256\n",
      "      I-PER     0.9324    0.9857    0.9583        70\n",
      "          O     0.0000    0.0000    0.0000       265\n",
      "      S-LOC     0.9334    0.9366    0.9350      1436\n",
      "     S-MISC     0.8477    0.8267    0.8370       525\n",
      "      S-ORG     0.9061    0.8919    0.8989      1082\n",
      "      S-PER     0.9241    0.8945    0.9091       531\n",
      "\n",
      "avg / total     0.8710    0.8721    0.8710      8377\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "bad_counter = 0  # number of epochs with no improvement on the validation test in terms of F1-score\n",
    "previous_best_valid_f1_score = 0\n",
    "epoch_number = -1\n",
    "\n",
    "while True:\n",
    "\n",
    "    step = 0\n",
    "    epoch_number += 1\n",
    "    print('\\nStarting epoch {0}'.format(epoch_number))\n",
    "\n",
    "    epoch_start_time = time.time()\n",
    "\n",
    "    if epoch_number != 0:\n",
    "        # Train model: loop over all sequences of training set with shuffling\n",
    "        sequence_numbers = list(range(len(dataset.token_indices['train'])))\n",
    "        random.shuffle(sequence_numbers)\n",
    "        for sequence_number in sequence_numbers:\n",
    "            transition_params_trained = train.train_step(sess, dataset, sequence_number, model, parameters['dropout_rate'])\n",
    "            step += 1\n",
    "            if step % 10 == 0:\n",
    "                print('Training {0:.2f}% done'.format(step / len(sequence_numbers) * 100), end='\\r', flush=True)\n",
    "\n",
    "    epoch_elapsed_training_time = time.time() - epoch_start_time\n",
    "    print('Training completed in {0:.2f} seconds'.format(epoch_elapsed_training_time), flush=True)\n",
    "\n",
    "    y_pred, y_true, output_filepaths = train.predict_labels_lite(sess=sess,model= model,transition_params_trained= transition_params_trained,\n",
    "                                                                         dataset=dataset,epoch_number= epoch_number,\n",
    "                                                                        stats_graph_folder= stats_graph_folder,dataset_filepaths= dataset_filepaths,\n",
    "                                                                        tagging_format= parameters['tagging_format'], main_evaluation_mode=parameters['main_evaluation_mode'],use_crf=parameters['use_crf'])\n",
    "\n",
    "       \n",
    "    if epoch_number % 5 ==0:\n",
    "        model.saver.save(sess, os.path.join(model_folder, 'model_{0:05d}.ckpt'.format(epoch_number)))\n",
    "        \n",
    "    if epoch_number > 10 :\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "prediction_count=0\n",
    "\n",
    "\n",
    "def predict(text):\n",
    "    #         if prediction_count == 1:\n",
    "    parameters['dataset_text_folder'] = os.path.join('..', 'data', 'temp')\n",
    "    stats_graph_folder, _ = utils.create_stats_graph_folder(parameters)\n",
    "\n",
    "    # Update the deploy folder, file, and dataset\n",
    "    dataset_type = 'deploy'\n",
    "    ### Delete all deployment data\n",
    "    for filepath in glob.glob(os.path.join(parameters['dataset_text_folder'], '{0}*'.format(dataset_type))):\n",
    "        if os.path.isdir(filepath):\n",
    "            shutil.rmtree(filepath)\n",
    "        else:\n",
    "            os.remove(filepath)\n",
    "    ### Create brat folder and file\n",
    "    dataset_brat_deploy_folder = os.path.join(parameters['dataset_text_folder'], dataset_type)\n",
    "    utils.create_folder_if_not_exists(dataset_brat_deploy_folder)\n",
    "    dataset_brat_deploy_filepath = os.path.join(dataset_brat_deploy_folder, 'temp_{0}.txt'.format(\n",
    "        str(prediction_count).zfill(5)))  # self._get_dataset_brat_deploy_filepath(dataset_brat_deploy_folder)\n",
    "    with codecs.open(dataset_brat_deploy_filepath, 'w', 'UTF-8') as f:\n",
    "        f.write(text)\n",
    "    ### Update deploy filepaths\n",
    "    dataset_filepaths, dataset_brat_folders = utils.get_valid_dataset_filepaths(parameters,\n",
    "                                                                           dataset_types=[dataset_type])\n",
    "    dataset_filepaths.update(dataset_filepaths)\n",
    "    dataset_brat_folders.update(dataset_brat_folders)\n",
    "    ### Update the dataset for the new deploy set\n",
    "    dataset.update_dataset(dataset_filepaths, [dataset_type])\n",
    "\n",
    "    # Predict labels and output brat\n",
    "    output_filepaths = {}\n",
    "    prediction_output = train.prediction_step_lite(sess, dataset, dataset_type, model,\n",
    "                                              transition_params_trained, stats_graph_folder,\n",
    "                                              prediction_count, dataset_filepaths, parameters['tagging_format'],\n",
    "                                              parameters['main_evaluation_mode'])\n",
    "    _, _, output_filepaths[dataset_type] = prediction_output\n",
    "    conll2brat.output_brat(output_filepaths, dataset_brat_folders, stats_graph_folder, overwrite=True)\n",
    "\n",
    "    # Print and output result\n",
    "    text_filepath = os.path.join(stats_graph_folder, 'brat', 'deploy',\n",
    "                                 os.path.basename(dataset_brat_deploy_filepath))\n",
    "    annotation_filepath = os.path.join(stats_graph_folder, 'brat', 'deploy', '{0}.ann'.format(\n",
    "        utils.get_basename_without_extension(dataset_brat_deploy_filepath)))\n",
    "    text2, entities = brat2conll.get_entities_from_brat(text_filepath, annotation_filepath, verbose=True)\n",
    "    assert (text == text2)\n",
    "    return entities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatting deploy set from BRAT to CONLL... Done.\n",
      "Converting CONLL from BIO to BIOES format... Done.\n",
      "Predict labels for the deploy set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1428: UserWarning: labels size, 4, does not match size of target_names, 17\n",
      "  .format(len(labels), len(target_names))\n",
      "d:\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "d:\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC     0.0000    0.0000    0.0000         0\n",
      "     B-MISC     0.0000    0.0000    0.0000         0\n",
      "      B-ORG     0.0000    0.0000    0.0000         0\n",
      "      B-PER     0.0000    0.0000    0.0000         3\n",
      "\n",
      "avg / total     0.0000    0.0000    0.0000         3\n",
      "\n",
      "Formatting 000_deploy set from CONLL to BRAT... Done.\n",
      "\n",
      "text:\n",
      "her name are Pham Ngoc Linh\n",
      "\n",
      "entity: {'id': 'T1', 'type': 'ORG', 'start': 13, 'end': 27, 'text': 'Pham Ngoc Linh'}\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'end': 27, 'id': 'T1', 'start': 13, 'text': 'Pham Ngoc Linh', 'type': 'ORG'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict('her name i Pham Ngoc Linh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
